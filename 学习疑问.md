# 查漏补缺

还需要学习的知识：HTTPS、分布式协议、计算机网络和操作系统还需要深挖



# 计算机网络

## 1、什么是CSRF？如何解决CSRF问题？
**描述**

​	CSRF，全称为跨站请求伪造，是一种常见的网络攻击手段，他是利用网站对用户浏览器的信任来达成恶意攻击的。一般的场景是恶意网站返回给用户的网页中包含一个重定向的请求（亦或是包含请求的按钮），如果用户访问了恶意网站，那么浏览器就会携带用户的cookie向重定向的目标发起请求，就可以完成一次恶意攻击（转账操作或者其他损害用户的操作）。

**解决方案**

1、检查HTTP中的Referer字段：在HTTP协议中，请求头中有一个referer字段，记录了http请求的来源地址，在访问安全受限的url时要求请求来源地址和访问的地址来自于同一个网站（同源策略），否则视为非法请求。

* 优点：简单易行，服务器只需要使用一个过滤器对安全敏感的请求进行处理就可以了。
* 缺点：仍然会有安全问题，http请求中referer字段的值是由浏览器提供的，虽然http协议上有明确要求，但是每个浏览器对于referer的具体实现可能有差别，并不能保证浏览器自身没有安全漏洞。使用这种方法，就是把安全性完全依赖于浏览器来保障，从理论上来讲，这样并不安全。事实上，对于某些浏览器，比如IE6或者FF2，目前已经有一些方法可以篡改referer的值。即使是使用最新的浏览器，黑客无法篡改referer的值，这种方法仍然有问题referer值会记录下用户的访问来源，有些用户会认为这样侵犯了其个人的隐私权，特别是有些组织担心referer值会把组织内网中某些信息泄漏到外网中，因此用户自己可以设置浏览器使其在发送请求时不再提供referer值。

2、在请求地址中添加token并验证：要抵御CSRF攻击，关键在于在请求中放入黑客不能伪造的信息，并且该信息不存在与cookie之中。服务端在用户登录后，为用户创建一个随机的token并存在session中，使用过滤器过滤请求并验证token。对于get请求，token将附在请求地址之后，对于post请求，要在form中加上token参数。

* 优点：比检查Referer要安全一些。
* 缺点：对于每一个请求，都要加上这个token参数，十分的麻烦，而且容易漏掉。

3、在HTTP头中自定义属性并验证：也是使用token并进行验证，和上一种方法不同的是，这里并不是把token以参数的形式放入HTTP请求中，而是以请求头中的属性的形式发送token。




## 2、什么是Oauth2.0协议？有哪几种认证方式？什么是JWT令牌？和普通令牌有什么区别？

​	Oauth2.0是一个开放标准，允许用户授权第三方应用程序访问他们存储在另外的服务提供者上的信息，而不需要将用户名和密码提供给第三方应用或分享他们数据的所有内容。



## 3、什么是XSS攻击？怎么预防XSS攻击？后端防御XSS攻击？

​	XSS攻击通常指的是通过利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。比如，用户自己填写的某些信息中，恶意用户填写的是一段JavaScript代码，当其他用户查看他的信息时，就会获取这段JavaScript代码，然后浏览器就执行了这段恶意代码，从而达到了恶意窃取用户信息等行为。

​	预防XSS攻击：

* 设置cookie为http only，这样JavaScript代码中就无法获得cookie的内容了，从而防止了用户信息被窃取。
* 对用户上传的数据进行过滤，过滤掉潜在的风险。



## 4、什么是HTTPS？和HTTP有什么区别？HTTPS的连接过程？

HTTP：

* 以明文方式发送内容，不提供任何方式的数据加密。
* 服务器端口号为80。



HTTPS：

* 在HTTP基础上加入了SSL/TLS协议，依靠证书验证服务器身份，并且为浏览器和服务器之间的通信加密。
* 服务器端口号为443。
* 工作过程为：
  * 首先建立到服务器端口443的TCP连接。
  * 然后进行SSL安全参数握手，在这一步骤中客户端需要验证服务器身份，获取其证书并验证得到公钥，然后随机生成一个对称式秘钥，使用服务器的公钥加密对称式秘钥，再发送给服务器，接下来就可以使用随机生成的对称式秘钥进行加密了。
  * 客户端在SSL上发送HTTP请求，SSL对HTTP请求进行加密，再交给TCP发送已加密的请求。
  * 服务器通过SSL加密HTTP响应，交给TCP发送给客户端。
  * SSL关闭通知。
  * TCP连接关闭。




## 5、TCP是如何保证可靠性的？TCP的可靠数据传输原理？

​	由于底层的网络传输信道是不保证数据传输的可靠性的，所以需要在传输层来做相应的可靠传输的保证。TCP通过checksum保证传输的报文不在网络传输过程中出现bit位错乱，通过超时重传机制来应对报文丢失的情况发生，通过流量控制来控制发送端发出报文的速率，通过拥塞控制来避免网络过于拥堵以至于出现崩溃的情况发生。

​	TCP的可靠数据传输原理：TCP是基于滑动窗口协议来发送报文的，也就是在发送端和接收端都设有缓存，下面进行详细的介绍。

​	滑动窗口协议：

* GBN协议：发送端的发送缓存可以同时发送多个分组，接收端的接收缓存只能接收一个分组，如果报文乱序到达接收端，则直接抛弃，也就是不支持乱序接收分组。当触发超时重传机制时，需要将发送窗口中所有分组重新发送，ack是累计ack，也就是对最近接收到的分组的ack。定时器只针对发送窗口中最早的分组进行设置。
* SR协议：发送缓存和接收缓存都可以同时处理多个分组，对于在接收窗口中的分组单独发送ack，发送窗口中的每个分组单独维护ack和定时器。超时重传只需要重传发送窗口中没有收到ack的分组，所以叫做选择重传。
* 两种协议比较：
  * GBN协议：**优点**是维护简单，只需要设定一个定时器，接收方只需要一个接收缓存。**缺点**是出错时需要将发送窗口中的所有分组都进行重传，代价太大。
  * SR协议：**优点**是出错时重传的代价小。**缺点**是对于发送窗口中的每一个分组，都要单独维护定时器，实现起来复杂，所需资源多，接收窗口可能需要缓存多个分组。



​	TCP实现的滑动窗口协议：结合GBN和SR协议进行改进。

* 发送缓存和接收缓存可以同时接收多个分组。
* 采用累积确认，如果收到乱序到达的分组，发送当前接收窗口中最低的已确认分组的ack。
* 快速重传机制：发送方如果收到3个冗余ack，则立即重传当前最低位的分组。
* 产生ack的细节：如果接收方接收到所期待的按序报文到达，并且所有之前的报文已经确认，则发送ack采用延迟策略，会延迟500ms，等待下一个顺序到达的报文（因为是累计确认，这样可以一次确认多个报文了）。如果等待期间另一个按序报文到达，则立刻发送ack，以确认两个报文段。
* 超时重传又与GBN不同：设当前报文段为n，如果当前定时器超时，GBN协议会重传n以及后续的所有报文段，而TCP协议至多只会传输一个报文段，即报文段n。



​	**流量控制**：

* 为什么要有流量控制？TCP协议是发送方和接收方都有缓存的，接收方的应用程序从接收缓存中读取所需要的数据，但应用程序不一定是接收缓存一接收到数据就进行读取了，也有可能过了很久才来处理这些数据，由于接收缓存是有限的，如果接收方应用程序的读取速度很慢，而发送方发送的太多，太快，就会导致接收方的接收缓存溢出。流量控制服务就是为了避免接收缓存的溢出而出现的机制。
* 流量控制是如何做到的？接收方通过TCP头部的一个字段（接收窗口）来告诉发送方，自己当前能接收的最大流量是多少。



## 6、有了TCP为什么还需要UDP？

​	因为UDP更快，UDP提供的是尽力而为的服务，不提供可靠性、流量控制、拥塞控制。

UDP更快体现在：

* 应用程序交付多少报文，就发出去多少报文，无拥塞控制和流量控制，不需要考虑网络拥堵情况。
* 不建立连接，减少了建立连接所需要的时间。
* 维护简单，发送方和接收方不需要维护连接状态。
* 报文段头部很小，开销小，一个报文段所能承载的信息也就更多。



## 7、TCP建立连接为什么是3次握手，而不是2次握手、4次握手？

​	首先，tcp建立连接的时候，客户端会和服务端交换字节序号，这个字节序号具有重要的作用。

​	如果是2次握手，那么服务器在向客户端返回字节序号信息时就已经当做连接建立了，此时就会有个问题：如果是由于网络阻塞或其他网络原因导致的客户端发出的历史连接请求现在才到达服务器端，而此时这个客户端已经关闭了连接（或者说不需要再和服务端建立连接了），那么服务端仍然会将这个连接请求当做正常的连接请求来处理，为这个连接维护资源。**这样就会导致服务器资源的浪费**。

​	如果是4次握手，其实没有必要，在3次握手时，服务端就已经可以得知客户端状态良好，并且是愿意建立连接的。已经能够确保服务器维护资源是有用的，所以没必要再多进行一次握手了。



## 8、TCP关闭连接为什么是4次挥手，而不是3次挥手？

​	由于TCP连接是全双工的，当客户端想要断开连接的时候，服务端可能还有数据要传送给客户端，所以整个断开连接的流程应该是客户端发起关闭连接请求，服务端收到并返回一个ack，同时服务端可以关闭自己的接收缓存（因为客户端不会再发送请求了）。如果服务端还有数据要发送，则等到发送完数据，服务端再向客户端发送关闭连接的请求，然后等待客户端返回ack，就可以彻底关闭连接了。而客户端这边，收到服务端关闭连接的请求后，需要再等待一段时间，防止由于网络传输出现问题导致服务端没有收到自己的ack。一段时间后，客户端没有再收到服务端的关闭连接请求（因为可能有超时重传情况出现），确认服务端已经收到自己的ack，彻底关闭连接。

​	为什么不能是3次握手？因为最后的时候服务端必须收到ack的确认之后才能关闭连接，不然无法确保客户端正确的接收到了自己发送的关闭连接请求。



## 9、为什么TCP被称为面向字节流的协议？UDP呢？

​	因为TCP协议构造报文时，将应用程序交付过来的数据视为字节流，并不为每个应用程序设置边界，不同的应用程序的数据有可能被构造成一个报文，这也就是所谓的**粘包**问题。

​	UDP是面向报文的协议，应用程序交付给UDP的报文，UDP只是在报文基础上加上一个头部，然后就交给下层了，不会对消息进行拆分，也就是说，应用层交给UDP的数据多长，UDP就发出多长，当然UDP的头部不算在内。

​	那如果应用层交付下来的数据非常的长，那UDP还是视为一个报文发出去吗？网络能够一次发这么多报文吗？需不需要限制应用层发下来的数据大小呢？

​	只要不超过理论上的限制（65507字节，后面单独开个问题解释），就可以视为一个报文发送出去，最底层一次发送的帧可能达不到那么多，但是在ip层的时候，就会将上层的数据进行分片了，所以UDP不需要考虑能否发送的问题，交由其下层实现。



## 10、什么是MAC地址？IP地址呢？两者有什么区别？

区别：

1、mac地址是48位，而IP地址是32位。

2、mac地址在网卡出厂时就唯一固定了，而ip地址可以分配给不同的主机。

3、ip地址使用层级式的管理，而mac地址是全局唯一。



## 11、路由选择算法有哪些？各有什么特点和区别？具体的实现算法？

### link state算法

​	链路状态算法

#### 工作过程

1、发现相邻节点，得到对方的网络地址。

2、测量到相邻节点之间的代价（延迟，开销）。

3、组装一个LS分组，记录它到相邻节点的代价情况。

4、每个路由器都通过上述步骤操作，获得全局拓扑信息。

5、使用dijkstra算法找出最短路径。

#### 问题

1、LS分组通过扩散的方式发到其他所有路由器，但是有可能造成无限扩散的问题。**解决办法**：通过增加顺序号来控制无穷的扩散，每个路由器都记录（源路由器，顺序号）的组合信息，发现重复的或者老的就不扩散。

2、顺序号循环使用问题，路由器崩溃之后序号从0开始，并且序号有可能出现错误。**解决办法**：LS分组增加年龄字段，生成一个分组时，年龄字段不为0，每一个时间段，年龄字段减1，年龄字段为1的分组将会被抛弃。这样序号错误的分组不会一直在网络中停留。

#### 算法整体步骤

1、为每个路由器节点维护一个二元组（d，v），d表示当前路由器到达这个节点的距离，v表示到这个路由器的路径中的上一个节点。

2、初始时，以当前路由器为起点，对当前路由器能够到达的其他路由器更新（d，v）二元组。其余无法到达的路由器的二元组为（∞，-）。

3、在所有的二元组中挑选出距离最小的一个，即d最小。

4、将这个最短的路由器加入结果集中并这个路由器更新其余的二元组。接着重复3和4步骤，直到所有的路由器都被固定下来。

#### 特点

* 需要路由器拥有**完整**的拓扑和边的代价信息。
* 基于dijkstra最小生成树算法。
* 算法时间复杂度为O(n^2)，利用堆能够优化到O(nlogn)的时间复杂度。
* 有可能会出现震荡，例如，当链路代价为链路承载的流量时。

#### 具体的实现

* OSPF协议，被用于Internet上。
  * 通告信息中包含：每一个邻居路由器一个表项。
  * 在IP数据报上直接传送OSPF报文（不通过UDP和TCP）。
  * 安全：所有的OSPF报文都是经过认证的，防止恶意的攻击。
  * 允许有多个代价相同的路径存在（RIP中只有一个），例如A -》 B -》 C的代价为10，A -》 D -》C的代价也为10，在OSPF中可以看到这两条路径，因为包含了全局的拓扑信息。
  * 对于每一条链路，对于不同的目标节点有多重代价矩阵。例如按照时间和延迟分别计算最优选择路径。
  * 对单播和多播的集成支持。Multicast（多播） OSPF使用相同的拓扑数据库。
  * 大型网络中支持层次性OSPF。

* ISIS协议，被用于Internet主干中，Netware，几乎和OSPF一样。



### distance vector算法

​	距离矢量算法

#### 工作过程

1、定期测量本节点到相邻节点的代价。

2、本节点根据相邻节点”声称“它们到目标节点的代价，计算出本节点经过相邻节点，到达目标节点的最小代价，并记录对应的下一个节点。

3、定期（或者DV有变化时）与相邻节点交换路由表。

#### 问题

1、无穷计算问题：好消息穿的快，坏消息传的慢

![image-20230221154639957](D:\文档\学习笔记\学习疑问.assets\image-20230221154639957.png)

​	最简单的例子：一开始，A和B之间的网络还没有断掉时，B将自己能够到达A的信息传递给C，C就可以计算出来自己到A的距离为C到B的距离加上B到A的距离。当A和B之间的网络不通时，B自己无法到达A节点，但是它收到了C传来的信息：C可以到A（C经过B到达A），就可以更新自己到达A的代价，但实际上，B已经无法到达A了。同样的，B会将重新计算的消息发送给C，如此循环往复，最终到达A的代价为INF，A不可达，这个过程需要经过很多的迭代，所以“坏消息传的慢”。

​	解决方法：水平分裂（split horizon）算法。C知道要经过B才能到达A，那么它传递给B的DV信息中到达A的代价为INF，而传递给其他相邻节点关于A的代价则为实际的代价。

2、环路问题：使用水平分裂算法之后，仍然还会有问题出现，当网络拓扑为环路的时候，水平分裂算法就无法解决问题了。

#### 特点

* 路由器只知道与它物理连接的邻居路由器，其余信息通过邻居路由器传递过来。

* 基于动态规划的算法。

* Bellman-Ford方程（动态规划）：d(i,j)表示节点i到节点j的最短路径，c(i,k)表示节点i到其相邻节点k的距离，满足以下方程

  > d(i,j)  =  min (  c(i,k)  +  d(k,j)  )

* 异步式迭代，每次本地迭代被以下事件触发：1、本地链路代价变化了；2、邻居发送来了DV的更新消息。

* 分布式：每个节点只是在自己的DV改变之后向邻居通知。

#### 具体的实现

* RIP协议
  * 每30秒在邻居之间交换一次通告报文。
  * 代价为跳数，即到达目标需要经过的路由数。
  * 每一个通告最多包括25个目标子网。
  * 最大跳数为16。
  * 180秒没有收到邻居的通告信息，则认为链路失效。
  * 使用毒性逆转阻止ping-pong回路（也就是环路问题）。毒性逆转的理念是当路由器发现网络中断后，在下次发送路由信息时不会忽略这个网络，而是将其跳数更新为协议跳数最大值+1，其他路由器收到信息时就会立刻知道该网络不可达，无需等待180秒（正常情况下需要等待180秒），大大加快网络收敛速度。
  * RIP以应用进程的方式实现：route-d(daemon)，通告报文通过UDP报文传送，网络层的协议使用了传输层的服务，以应用层实体的方式实现。



### 对比

1、消息复杂度：DV胜出。LS需要每个路由器都拥有全局的网络拓扑信息；而DV只需要和邻居交换信息。

2、收敛时间：LS胜出。LS使用dijkstra算法，拥有全局的拓扑信息，时间复杂度为O(n^2)；DV收敛较慢，需要经过多次迭代才能生成全局的拓扑信息，并且由于存在环路问题，有可能需要非常久的时间才能收敛。

3、健壮性：LS胜出。LS需要获取全局的拓扑信息，节点会通告不正确的链路代价，每个节点单独计算自己的路由表，错误信息影响较小；DV采用迭代式的计算，存在环路问题，且每一个节点的路由表会被其他节点使用，错误的计算可能扩散到全网。

总结：两种路由选择算法都有其优缺点，而且在互联网上都有应用。



## 12、第四次挥手为什么要等待2MSL？而不是1MSL？

1、等待是为了防止服务器没有收到ack，最后再次发送一个请求关闭的报文。

2、2msl是为了保障在本次连接中所有的通信报文都失效。



## 13、HTTP1.0/1.1/2.0/3.0有什么区别？

1.0：

* HTTP1.0采用短连接，每发送一个请求就需要建立一个TCP连接，当客户端收到响应之后就关闭当前TCP连接，频繁的创建和关闭TCP连接非常耗时。

1.1：

* 采用长连接（通过设置Connection属性为keep-alive或keep-alive:timeout），改善了TCP连接频繁创建和关闭的问题，在一次连接中可以发送多次请求。
* 支持管道传输，发送HTTP请求时不必等待前一个请求得到响应，就可以发送下一个请求，但服务端还是要顺序处理HTTP请求，如果A请求先到达服务端，但是处理耗时要很久，那么后续到达的B请求要等到处理完A请求之后才能得到响应。

2.0：

* 采用头部压缩，如果客户端同时发出多个请求，它们的头部是一样或相似的，那么协议会帮助消除重复的部分，原理是客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，后续就不用发送相同字段了，只需要发送索引号。
* 使用二进制格式，不再像1.1中的纯文本格式的报文，而是全面采用了二进制格式，头和数据体都是二进制，统称为帧，收到报文后无需将报文转成二进制，可以直接解析二进制报文。
* 多路复用，在二进制分帧的基础上，使用多路复用技术，使得一个连接中可以并发处理多个请求，并且不用按照顺序处理，服务端在处理A请求时发现A请求处理过程非常耗时，所以先将A请求的部分响应发送回客户端，然后处理后面的请求，后续要接着处理A请求。由二进制分帧层来对请求和响应的帧进行组合。
* 服务端推送，服务端可以主动向客户端发送消息，传统的HTTP协议中是请求应答式的交互，服务端不能够主动的联系客户端，使用服务端推送，可以提前将客户端所需要的资源发送过去，比如请求html文件时需要的css、js文件，减少延时。



## 14、TLS有几次握手？

### 第一次握手

​	客户端向服务器发送Client hello，消息明文传送，包括客户端支持的协议版本、支持的压缩算法、加密套件（认证算法、秘钥交换算法、对称加密算法和信息摘要算法）、客户端生成的随机数R1、扩展字段等。

### 第二次握手

​	1、收到客户端发送的client hello，服务器将发送server hello消息进行响应，消息明文传输，包括确认使用的协议版本、服务器生成的随机数R2、确认使用的加密套件、确认使用的压缩算法。

​	2、发送完server hello后，服务端将自己的公钥证书发送给客户端。

​	3、Server Key Exchange并非必须选项，只有选用了DH算法的情况下服务器需要将DH参数发送给客户端，若选用了RSA算法则不需要进行Server Key Exchange。

​	4、Certificate Request也并非必须选项，在对于安全性要求较高的场景中，服务器要对客户端的身份进行认证，因此发起了对客户端公钥证书的请求，一般情况下浏览器都会内置一对独一无二的公私钥。

​	5、由于第二次握手中包含一些可选项（例如3和4），因此服务器需要发送一个server hello done的消息，表示服务端已经发送完第二次握手的信息了。

### 第三次握手 

​	客户端收到server hello done之后并没有马上进行第三次握手，而是先对服务器传来的证书进行验证，一般检验证书是否在有效期内，根据CRL或OCSP查询证书是否有效，最后根据证书链从CA开始验证直到网站证书，确保证书的真实性，如果验证过程不通过，则按照错误来处理；验证通过，就再生成一个随机数Pre-master，并用服务器公钥进行加密，生成PreMaster key。

​	1、Client Key Exchange阶段，客户端将PreMaster key发送给服务器，服务器则会用自己的私钥解密出Pre-master。此时客户端和服务器都拥有了三个随机数R1、R2和Pre-master，两边再用选定的算法和三个随机数生成一个对称式秘钥，用于握手结束后传输数据的对称加密。

​	2、Change Cipher Spec阶段，客户端向服务器通知，后面发送的消息都会使用协商出来的秘钥进行加密。

​	3、Encrypted Handshake Message，客户端向服务端发送握手数据加密信息，该信息是客户端将前面的握手消息利用协商好的摘要算法生成摘要，再用协商好的秘钥对摘要进行加密而得出来的，最后将加密信息发送给服务器，这是客户端发出的第一条加密信息，服务器也会用协商好的秘钥进行解密，成功解密则说明协商的秘钥是一致的。

​	4、Certificate，在第二次握手的第4步进行的情况下，即服务器向客户端请求证书的情况才会有的，这一步是客户端向服务器发送自己的证书，服务器收到后也会进行相应的验证。

### 第四次握手

​	1、Change Cipher Spec，服务器向客户端发送通知，告知后面的消息都会有协商出来的秘钥进行加密。

​	2、Encrypted Handshake Message，和第三次握手类似，是服务器发送给客户端的用来确定协商的秘钥是一致的，也是一条Server Finish消息。



## 15、对称式加密和非对称式加密有什么区别？



## 16、什么是证书、证书链？

​	证书是对公钥的进行身份验证的一种文件，由权威机构CA颁发。服务器获取证书的流程：将自己的公钥和身份验证的信息（例如域名）交给CA，CA进行验证后，会生成一份文件，包含：服务器的公钥、服务器的域名、证书有效时间、颁发者信息、使用的摘要算法等，此时这份文件还不完整，还需要对这份文件通过摘要算法计算出摘要，然后CA再使用自己的私钥对摘要进行加密（又称为数字签名），然后将这部分信息也放入证书中。

​	由权威机构认证过的服务器也可以对其他服务器颁发证书，这就形成了一种信任链的关系，所以就有了证书链这么一种关系。

# 数据结构与算法

## 1、什么是并查集？并查集能做什么？

​	我的理解：并查集是一种数据结构，它可以帮助我们将元素归为多个组，用以区分不同的元素组。

​	百度百科：并查集是一种树型的数据结构，用于处理一些不想交集合的合并及查询问题。



## 2、什么是单调栈？单调栈能做什么？
我的理解：
* 单调栈是一种特殊的栈数据结构，特殊之处在于它其中存储的元素都是按照一定的策略，单调增/减的。
* 典型的考察单调栈的题目有《滑动窗口的最大值》



## 3、什么是树状数组？树状数组能做什么？
我的理解：
* 树状数组是一种按照特殊策略维护的前缀数组，由于其维护方式很像是树形，但实质上是使用数组结构，所以一般称为数组。
* 树状数组用于动态维护前缀和，比如当我们的需求需要频繁的修改前缀和，如果使用传统的数组来进行更新的话，时间复杂度是O(n)，修改一个元素，那么这个位置以及后边的所有位置的前缀和都需要修改。如果使用树状数组的话，能够将时间复杂度减低到O(logn)级别。


## 4、什么是线段树？线段树能做什么？



## 5、什么是拓扑排序？



## 6、什么是差分数组？





# 操作系统

## 1、操作系统是如何保证多个线程之间不会相互访问到彼此的内存的？

​	每个线程都有自己的栈内存，如果是使用局部变量的话，局部变量只能保存在栈内存中。



## 2、操作系统是怎样为每个线程分配一个栈的？



## 3、什么是LRU算法？如何实现LRU算法？如何优化？

​	LRU（Least Recently Use），中文意为最近最少使用算法，常用于缓存替换策略，将最近一段时间内最少使用的缓存内容换出。

​	**LRU的简单实现**：使用Hash表+双向链表，Hash表中存放当前缓存中拥有的数据，在双向链表中存放这些数据添加进来的顺序，如果缓存命中了，则更改它在链表中的顺序，调整为队头；如果缓存满了，此时还需要加入新的缓存，则淘汰掉队列尾部的缓存内容。

​	**优化**：

* LRU-K：采用LRU-K改进LRU算法，LRU-K的实现是使用两个队列，一个是缓存队列，一个是访问数量统计队列，访问某个内容之后，并不是直接将其加入到缓存中，而是将其加入到数量统计队列中，当访问数量达到K次后，再将其放入到缓存队列中。而数量统计队列的维护也是有上限的，其也采用LRU算法淘汰太久没有被访问过的数据。
	 * 为什么要访问数量达到K次后才放入到缓存队列中？因为这样做可以避免缓存污染，比如某一个请求需要查询出所有的数据，而这些数据并不是接下来将会经常访问的数据，导致缓存内容会被频繁的换出，这就是缓存污染。
	 * 缺点是需要额外维护一个统计队列，占用系统资源。
	 * 综合来说，使用LRU-2性能最优，为什么？
* Two Queue：和LRU-K基本上一样，是LRU-2的变种，数量统计队列采用FIFO算法，而不是LRU，实现更简单，消耗资源少，但相比于LRU-2会降低缓存命中率。
* Multi Queue：也可以看作是LRU-K的变种，只是将两个队列增加至了多个队列，每个队列的优先级不同，首次访问数据时，数据会被添加到最低优先级的队列中，每个队列中同样采用LRU，当数据的访问次数达到一定时，将会”晋升“至更高优先级的队列中，而访问次数不达标时，还会从当前队列降级到第一级的队列中。除此之外，还有一个额外的队列（Q-history）用来存储即将被淘汰的数据，淘汰总是从最低级的缓存队列进行的，当缓存队列满了的时候，会将队尾数据加入到Q-history中，当Q-history中的数据被再次访问时，会计算其的优先级，然后加入到相应优先级的队列中。
* MySQL中的LRU：在MySQL中，数据（一行记录）是以页为单位存储的，读取到内存缓冲区的时候也是以页为单位来读取（可能？），由于MySQL在内存中的缓冲区大小是有限的，所以也需要使用LRU算法来缓存页。不过MySQL中使用的LRU相比于普通的LRU更为特殊，用语言描述，它更像是一种冷热分离的LRU算法，因为它的LRU实现是访问数据后，不是将数据插入到链表的头部，而是插入到链表的midpoint位置，这个midpoint是由MySQL的参数innodb_old_blocks_pct控制的，默认配置下，是在链表长度的5/8处。在Innodb存储引擎中，把midpoint前的部分称为new列表，后面部分称为old列表。
   * 为什么要采取这样的一种插入策略呢？因为在MySQL中，没有使用索引的全表扫描（即使使用了索引，也有可能需要访问大量的数据页），会需要访问大量不同的数据页，从而将缓冲中很多数据都刷新出缓存，后续不能再命中这些缓存。为了解决这个问题，innodb存储引擎还引入了另外一个参数来进一步管理LRU缓存：innodb_old_blocks_time，这个参数表示在页加入midpoint多少时间之后，再将页放入到链表的头部。因此，我们可以使用这个参数来解决全表扫描造成大量有效页被刷新出缓存，例如，在进行全表扫描的查询操作之前，将innodb_old_blocks_time设置为一个很大的数，这样midpoint之前的数据都不会被刷新出缓存，在全表扫描完成之后，再将innodb_old_blocks_time参数设置回适合的值。



## 4、什么是高速缓存的局部性原理？

​	**我的理解**：

* 时间局部性：由于循环的存在，内存中访问过的指令可能在不久的将来就会再次访问到。
* 空间局部性：内存地址中相邻的指令或内存很可能也会被访问到，比如遍历数组、顺序执行程序。

	综合这两点来说，我们的程序执行时，很可能在某段时间内，执行的是同一段内存地址中的指令或访问的是同一段连续的内存，所以，我们可能只需要很小的一块高速缓存，也可以做到高速的执行。
		
	**CSAPP**:
		
	程序具有访问局部区域里的数据和代码的趋势。通过让高速缓存里存放可能经常访问的数据，大部分的内存操作都能在快速的高速缓存中完成。
		
	**存储器层次结构的主要思想是上一层的存储器作为低一层存储器的高速缓存。**



## 5、什么是进程？线程？协程？它们有何区别？

​	**我的回答**:

* 我觉得进程就是运行中的程序，操作系统为了更好的管理这些程序，并且要做到同时执行多个程序，所以操作系统使用一个数据结构PCB来定义正在执行的程序，这个数据结构保存当前程序执行的信息，还有操作系统分配的资源，比如页表、PC寄存器的值，都会保存在PCB中。一个PCB就代表了一个正在执行中的程序，也就是一个进程。
* 对于每个进程，操作系统都会分配内存资源，进程在上下文切换时的开销就会很大。为了减少上下文切换的开销，就引出了线程的概念，一个进程中可以包含多个线程，这多个线程共享这个进程所分配的内存空间，所以线程切换的时候开销小，可以将更多的时间用在执行程序上。
* 线程的切换，需要进入内核态执行，虽然相比于进程来说，线程的切换开销比较小，但是依然需要使用很多的系统资源，所以，这时候引出了协程，协程是运行在用户态的，所以操作系统感知不到协程的存在，多个协程可以跑在一个线程之上，而协程的切换只需要在用户态做处理，切换开销极小。
* 对于每个进程，操作系统都会为其分配内存和其他系统资源，也就是说，每个进程之间的系统资源和内存是独立的；而多个线程是共享一个进程中的内存和系统资源的，有可能造成安全问题；相比于线程，协程可以由程序员自己进行负责调度，避免了无意义的调度，并且更加轻量级，由此可以提升性能，但协程不适用于阻塞IO的场景，因为阻塞时，当前线程进入内核态，操作系统并不知道协程的存在，会将这个线程阻塞住，切换到别的线程执行，而运行在这个线程之上的所有协程都将会被阻塞住，无法运行。
* 总结来说，进程主要负责资源的保护和管理，线程主要关注中央处理器的执行，而协程则是更近一步提高并发执行能力。



​	**知乎链接**：

* 什么是协程：https://zhuanlan.zhihu.com/p/172471249



## 6、什么是保护模式和实模式？为什么要使用保护模式？

​	**我的回答**：计算机刚开始启动时，需要执行初始化代码，初始化代码一般存在内存中0xFFFF0处，此时CPU处于实模式，寻址方式为CS（段寄存器）左移4位+IP。而进入保护模式之后，不再是直接通过CS+IP的方式来寻址，而是使用gdt表进行地址翻译，使用idt表处理中断指令，具体的做法是使用CS寄存器中的值去gdt中查找对应的记录项，然后再和IP组合起来形成物理地址。

​	使用保护模式的好处是能够实现更大的地址空间和更灵活更安全的内存访问，例如可以在gdt表中存放一些标识，来判别当前程序是否能够访问此内存地址以及其他的一些控制信息。



## 7、操作系统怎样判断是否进入了保护模式？

​	使用cr0寄存器来判断，cr0寄存器的最低位标识是否进入了保护模式，如果是1的话，表示启动了保护模式，否则是未启动。同时cr0寄存器还有另一个作用，它的最高位标识是否启动分页，如果为1表示启动分页。



## 8、计算机是怎样启动的？

​	首先，刚开机时CPU处于实模式，CS=0xFFFF，IP=0x0000，寻址0xFFFF0（ROM BIOS）处执行初始化代码，检查RAM，键盘，显示器，软硬磁盘等工作，然后将磁盘0磁道0扇区（引导扇区）读入到0x7c00处，然后跳转到引导扇区代码bootsec中执行，在bootsec中，将setup模块和system模块读入到内存中，然后进入setup执行，setup模块中完成OS启动前的设置，包括设置内存大小，各种硬件参数等等，便于后续操作系统管理硬件，然后setup模块将system模块移动到0地址处，并且设置gdt表，操作系统即将进入保护模式，保护模式的寻址方式和实模式不同。然后跳转到system模块运行，首先干的一件事就是再次初始化gdt和idt表，然后初始化页表，进入main函数执行一系列初始化，包括内存、中断、设备、时钟、CPU等内容的初始化。



## 9、什么是操作系统接口？

​	操作系统接口就是操作系统提供给上层应用程序调用的函数，屏蔽了驱动硬件的细节，让应用程序开发人员能够方便快捷的使用操作系统提供的功能。



## 10、为什么操作系统要分用户态和内核态？如何区分内核态和用户态？用户程序如何进入内核模式执行所需的代码?

### 为什么区分：

​	首先，用户态和内核态是什么？用户态就是程序员们开发的应用程序运行时使用的内存地址空间，而内核态是操作系统运行所使用的的内存地址空间，内核态中存放了很多管理电脑使用的数据结构和数据，如：PCB、FCB、内存表（mem_map）、内存大小参数等等。

​	为什么要将应用程序和操作系统分开？如果没有区分用户态和内核态，那么一个应用程序就可以随意的访问到所有重要的系统资源信息，也可以随意的篡改这些系统信息，不安全。试想一下，如果多个用户同时操作一台计算机，而没有区分用户态和内核态的话，用户A操作的数据在内存中，而用户B可以访问这些数据，同时所有用户都可以看到存在内存中的操作系统数据，包括每个用户的信息等等。

### 如何区分：

​	使用CS寄存器的最低两位（CPL）来表示当前是在用户态还是在内核态中，0是内核态，3是用户态，而目标内存地址的段寄存器值的最低两位为RPL。在保护模式下，对于要访问的内存地址，需要查询GDT，而在GDT中会记录目标内存地址的DPL（Descriptor Privilege Level），每一次访问内存地址时，都需要进行特权级检查，只有当DPL>={CPL,RPL}时，才允许进行访问。

### 用户态如何进入内核态执行：

​	对于Intel x86，使用中断指令int，可以进入内核态执行，int指令将CS中的CPL改成0，从而就可以进入内核了，这是用户程序进入内核态执行的唯一方式。



## 11、什么是系统调用？系统调用有什么用？系统调用是怎么实现的？

​	系统调用就是操作系统提供给应用程序使用的功能接口，例如读取文件、创建线程，由于这些功能是由操作系统实现的，而开发应用程序需要使用这些功能，所以操作系统提供了系统调用这样的接口给应用程序使用。

​	系统调用使用户程序能够进入内核态执行操作系统代码，而且用户程序只能通过系统调用才能进入内核态执行。这是因为操作系统需要保证计算机运行的安全，如果用户程序能够随意进入内核执行，随意的访问底层数据，调用底层方法，那么就有可能有恶意分子随意更改其他用户的文件信息。

​	操作系统通过段寄存器CS的低2位来判断当前执行的程序是处于用户态（值为3）还是内核态（值为0），这个信息叫做**特权级**，只有当特权级为内核态时，才能够跳转到内核态中的目标代码中执行。每当执行函数调用的时候，都需要判断当前代码的特权级和目标代码的特权级是否符合符合要求，如果不符合要求，则不允许跳转执行。而系统调用通过idt表来进行函数跳转（保护模式），而idt表中的特权级设置为3，这样，即使是处于用户态的程序也可以跳转到这个函数中执行。



## 12、gdt、ldt、idt分别是什么？为什么需要它们？

​	gdt是全局描述符表，主要是用于保护模式中进行地址转换时使用。段表的作用有：权限控制（特权级判断）。

​	ldt是局部描述符表，是每个进程独有的段表，因为进程之间的内存是相互隔离的，每个进程都有自己的代码段、数据段等，所以每个进程都要有自己的段表。

​	idt是中断向量表，是执行中断指令时需要查询的。



## 13、CS:IP和PC寄存器有什么区别？

​	网络上也没有详细对比这两者的文章，但是有文章说CS:IP用于寻址，而PC是不同厂商对这种寻址寄存器的称呼。

​	我个人的理解是，这两种寄存器在功能没有区别，都是完成指令寻址功能，而在具体的实现上有所区别。



## 14、按位编址和按字节编址有什么区别？

​	按位编址表示一个数字代表一个位，而按字节编址表示一个数字代表一个字节，使用字节编址，使用更小的数字能够表示更大的内存。



## 15、CPU调度算法的性能评价标准是什么？各评价标准的影响因素是什么？

​	**CPU利用率**：CPU有效执行的时间/总时间。如果频繁的发生线程上下文切换，那么CPU很大一部分的时间都花费在切换上了，而没有使用在运行程序上。

​	**周转时间**：批处理用户从作业提交开始，到作业完成为止的时间称为作业周转时间。

​	**吞吐量**：单位时间内系统完成的任务数量。对于很多批处理程序来说，吞吐量越大越好。

​	**响应时间**：用户提交一个请求到接收到响应之间的时间称为响应时间。



## 16、CPU调度算法是什么？为什么需要？有哪些CPU调度算法，各自的优缺点是什么？

​	**是什么**：CPU调度算法是CPU执行线程/进程上下文切换时挑选线程/进程使用的策略。

​	**为什么**：好的CPU调度算法能够极大的提升计算机性能，或者给用户更好的体验，由于计算机的使用范围极为广泛，不同的使用场景使用不同的调度策略能够更好的利用计算机。

​	**有哪些**：批处理系统的调度算法：先到先服务（FCFS）、短任务优先（SJF）、响应比优先。分时系统的调度算法：时间片轮询、多级反馈队列。

- 先到先服务

  - 优点：实现简单，消耗资源少。
  - 缺点：适用性差，比如，当前计算机的使用场景是用户使用，那么它应该要给用户良好的使用体验，即对用户的响应要快，这时如果有一个耗时很长的后台任务来了，那么它将会占用cpu很久，以至于用户已经等的不耐烦了。简单来说，任务如何执行，完全取决于任务提交的时机，这是非常不可控的。

- 短任务优先

  - 估计运行时间短的任务优先被调度。

  - 优点：适合需要高响应的使用场景。
  - 缺点：会出现饥饿现象，如果不断的有短任务提交，那么耗时较长的任务将会得不到执行机会，这是一个致命缺陷。不适合科学计算等需要高吞吐量、高利用率的场景，因为短作业优先算法会频繁的发生上下文切换，即使线程的切换代价相比于进程切换已经小了很多，但依然是一笔不可忽视的开销。

- 响应比优先

  - 结合等待时间和估计耗时，计算公式为：响应比 = 1 + 等待时间/估计运行时间。
  - 优点：不会出现饥饿现象，又保证了短任务优先执行，估计运行时间越小，响应比越高，所以就越先执行；而估计运行时间长的任务，随着等待时间的增加，响应比也会越来越大，最终额能够获得执行机会。
  - 缺点：以周转时间作为性能的衡量标准的话，响应比优先调度算法的性能是介于短作业优先和先来先服务之间的。

- 时间片轮询

  - 给每个进程分配一个执行时间片，然后按照先到先得的顺序执行，时间片消耗完后将执行权交给下一个进程，如果任务没有执行完，重新进行排队。
  - 优点：实现简单，每个进程都有同等的运行时间，都有机会获得执行机会，不会出现饥饿现象。
  - 缺点：对于所有的进程一视同仁，特定场景下执行没有优势；进程频繁切换，执行效率不高。

- 多级反馈队列

  - 在时间片轮询的基础上设置多个就绪队列。1、每个就绪队列的优先级不同，不同队列中的进程有不同的时间片优先级越高的队列，拥有的时间片越短。2、在就绪队列中使用先到先得的调度算法，而最后一个就绪队列采用时间片轮询算法。3、不同就绪队列中采取抢占式调度，如果当前进程执行时，有新的进程进入了优先级更高的就绪队列中，则新进程夺走当前进程的执行权，当前进程进入下一个就绪队列中执行。4、新创建的进程总是从优先级最高的就绪队列开始执行，如果时间片用完了，进程任务还没执行完，则进入下一级就绪队列中等待执行。
  - 优点：适用于不同情况，能使各类用户获得较为满意的性能。
  - 缺点：实现复杂。



## 17、什么是虚拟内存？为什么要使用虚拟内存？

**是什么：**虚拟内存是操作系统对物理内存的虚拟化，通过这种虚拟化技术，让每个进程都像是在使用完整的物理内存一样。

**为什么：**

* 使用虚拟内存，能够**高效的利用物理内存**，利用程序执行的局部性原理，只加载一个进程中频繁使用的内存到物理内存中，这样其他的进程能够利用的物理内存空间也就多了。
* 为每个进程提供了一致的地址空间，**简化了内存管理**，所有进程拥有的地址空间都是一致的，管理起来很方便，试想一下，如果不使用虚拟内存，每个进程使用的都是物理内存，那么一定会出现不同的进程所使用的地址空间是不同的，因为进程之间的内存要进行隔离，一句话概括就是：公司采用统一的规定是不是更好管理？如果针对每个人指定不同的制度，管理起来就非常困难。
* 保护了每个进程的地址空间不被其他进程破坏，提供**内存保护**的能力。

**特点**



## 18、操作系统层面如何优化程序？

1、减少过程调用。

2、消除不必要的内存引用。

3、循环展开。

4、多个累积变量。

5、书写适合用条件传送实现的代码。



## 19、硬链接和软链接？

首先明确，每个文件对应一个索引节点（inode）。

硬链接：两个不同的文件指向同一个索引节点，索引节点的links字段值为2。

软链接：软链接文件的数据块中存储着指向实际文件的地址。

参考文章：https://ee.ofweek.com/2021-06/ART-11000-2800-30504677.html



## 20、什么是VFS？有哪些VFS？

​	VFS意为虚拟文件系统，是Sun microsystems公司在定义网络文件系统时创造的，是允许和操作系统使用不同的文件系统实现的接口。虚拟文件系统是物理文件系统与服务之间的一个接口层，它对Linux的每个文件系统的实现细节进行抽象，使得不同的文件系统在Linux核心以及系统中运行的其他进程看来，都是相同的。VFS并不是一种实际的文件系统，它只存在于内存中，不存在于任何外存空间。VFS在系统启动时建立，系统关闭时消亡。

# 分布式

## 1、CAP是什么？怎么理解分区容错性？

​	C：Consistency，一致性

​	A：Availability，可用性

​	P：Partition Tolerance，分区容错性

​	CAP理论：一个分布式系统不可能同时很好的满足一致性、可用性、分区容错性这三个需求。

**理解分区容错性**

​	当一个分布式系统由于网络问题，被分为多个网络分区之后整个系统仍然能够正常工作。要么牺牲可用性，停止系统用于错误恢复，要么继续服务，但是降低一致性。



## 2、Eureka的自我保护机制是什么？

​	是指短时间内，出现了Eureka与大量的服务联系不上（90秒没有收到心跳包）的情况下，Eureka选择不删除（下线）这些服务。这是因为短时间内如果出现大量的微服务下线，则有可能微服务本身没有问题，而是由于网络分区的故障（可能是当前Eureka服务器的网络出现了问题），导致服务暂时不可用，Eureka为了确保高可用，宁可保留着错误的服务，也不会随意下线服务。**属于CAP中的AP分支**。



## 3、什么是服务雪崩？该如何解决？

​	这篇文章讲的应该还不错：https://www.jianshu.com/p/acfb4ac2b124。

​	服务雪崩是由于服务提供方不可用或响应慢，导致服务调用方不可用或响应慢，并且影响逐渐扩大的情况。我的理解是：由于服务中的一个接口出了问题，导致整个服务不可用，从而导致其他调用此服务的服务也不可用，就像雪崩一样。

​	解决方案：**服务熔断**、**服务降级**。使用”断路器“，当某个服务发生故障之后，通过断路器的检测，向调用方返回一个符合预期的、可处理的备选响应，而不是长时间的等待或者抛出调用方无法处理的响应，这样就保证了调用方的线程不会被长时间、不必要的占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。



## 4、什么是服务降级？服务熔断呢？

​	服务降级：服务器繁忙或出现异常，为了不让客户端等待，立即返回一个友好提示。

​	服务熔断：在一段时间内，服务器多次请求超时或出现异常，则对接下来的请求无需等待，直接调用服务降级的方法返回友好提示。

​	我的理解：服务降级就相当于提供一个兜底的方法，一般情况下，只有请求的服务出现了异常或者超时，才需要进行服务降级。而服务熔断的时候，不管当前请求会不会出现异常，都直接按照服务降级来处理。

​	**案例：**服务提供者B提供两个接口，一个正常返回结果，一个等待3秒后返回结果（模拟服务响应慢导致请求超时），服务消费者A可以调用服务提供者B的两个服务，此时使用测压工具模拟大量并发请求去请求服务B的超时接口，将会导致服务B的线程池被占满，从而导致服务B的其他服务也不可用，这时候再使用服务A去调用服务B，服务A也会陷入等待，直到超时。最终的结果就是服务A也被拖垮了，这就形成了上面的服务雪崩的情况，此时应该使用服务降级来避免这种情况的发生，在服务A请求服务B未果后，应该返回一个兜底的方法处理结果，而不应该继续等待。



## 5、服务提供和服务消费使用Hystrix的区别？

​	**服务提供方：**需要在业务方法上加上@HystrixCommand注解，然后在主启动类上添加@EnableCircuitBreaker注解进行激活

​	**服务消费方：**在YML配置文件中进行配置

~~~yml
feign:
  hystrix:
    enabled: true #如果处理自身的容错就开启。消费端开启方式与生产端不一样。
~~~

​	然后在主启动类上添加@EnableHystrix注解，最后在业务方法上添加@HystrixCommand注解。



​	**服务调用方使用服务降级的不同方法**

* 在业务代码中使用@HystrixCommand，业务controller上使用@DefaultProperties指定默认的兜底方法。
  * 缺点：和业务代码耦合在一起，维护起来很麻烦。
* 编写feign接口的实现类，在实现类中为调用方法提供兜底方法，然后在父接口@FeignClient注解中指定fallback属性为实现类。
  * 缺点：这种方法是不是要给每个方法都提供一个兜底方法？那就太麻烦了。



## 6、Hystrix断路器工作原理？

​	Hystrix断路器会在一定时间内（时间窗）统计请求失败的次数，当这段时间内的请求次数达到了阈值，并且请求失败的比例超过了规定的比例，则断路器打开（注意这个打开的意思是断路器开始工作），接下来一段时间（休眠窗口）内的所有请求都直接走服务降级流程，过了一段时间后（休眠窗口），断路器进入半开状态，会放一条请求去实际调用服务，如果这次请求成功了，则服务恢复了正常，断路器关闭（停止工作）；如果失败了，断路器继续工作，直到下一个周期再放一条请求进来，重复这个步骤。

​	断路器的三个状态：打开、半开、关闭。服务正常时，断路器的状态是关闭的；当一定时间内，请求数量达到阈值，请求失败比例达到阈值，断路器进入打开状态；进入打开状态一段时间后（休眠窗口），进入半开状态，服务有机会恢复成正常状态。



## 7、分布式微服务项目中网关的作用是什么？为什么选择Gateway而不选择Zuul？

​	能够进行反向代理（分发请求给具体某个服务实例）、权限校验、流量监控、服务熔断、日志监控等功能。

​	为什么选择Gateway：

* Zuul1.0已经进入了维护阶段，而Gateway是springcloud团队研发的，功能更多，用起来也方便。而Zuul2.x版本SpringCloud似乎并没有整合计划。
* SpringCloud Gateway具有的特性：动态路由、可以对路由指定断言和过滤器、集成了Hystrix的断路器功能、集成服务发现功能、请求限流功能、支持路径重写。
* Zuul1.x是一个基于阻塞I/O的API网关，基于Servlet2.5，不支持任何长连接，性能较差；SpringCloud Gateway使用非阻塞I/O，支持WebSocket。



## 8、向微服务项目发送请求，请求的处理过程是什么样的？网关和服务调用方的区别是什么？

​	请求应该是先到达网关，然后网关再进行动态路由，将请求分发给对应的微服务。

​	一开始我以为服务调用方是微服务对外暴露的，但实际上对外暴露的应该是网关才对，也就是说，网关和我前面所学的例子中的服务消费者的作用是一样的。我的理解是：在微服务项目中，由于各个服务之间需要相互调用，所以每个微服务可能既是服务调用者，也是服务提供者，而最开始我认为的服务调用者的身份，其实是网关来充当的。



## 9、SpringCloud Stream是什么？有什么作用？

​	为了解决项目中使用到多种不同的消息中间件的时候，不同的消息中间件处理起来是完全不同的，如果要迁移的话，一大堆东西都要推倒重做，因为具体的发布和订阅代码和我们的系统耦合了，这时候使用SpringCloud Stream，可以帮助我们消除这种耦合。

​	SpringCloud Stream通过定义绑定器Binder作为中间层，实现了应用程序与消息中间件细节之间的隔离。



## 10、什么是漏桶算法？

​	漏桶算法是网络世界中流量整形或速率限制时常用的一种算法，它的主要目的是控制数据注入到网络中的速率，平滑网络上的突发流量。



## 11、为什么要使用消息队列？什么情况下应该使用消息队列？

​	消息队列作用：消峰、异步、解耦



## 12、Seata是怎么做到保证分布式事务的回滚和提交的？

### Seata主要构成	

Seata分布式事务处理过程：ID+三组件

* 全局唯一的事务ID：Transaction ID，XID。
* Transaction Coordinator(TC) ：事务协调器，维护全局事务的运行状态，负责协调并驱动全局事务的提交或回滚。
* Transaction  Manager(TM) ： 控制全局事务的边界，负责开启一个全局事务，并最终发起全局提交或全局回滚的决议。
* Resource Manager(RM) ：控制分支事务，负责分支注册，状态汇报，并接收事务协调器的指令，驱动分支（本地）事务的提交和回滚。

![image-20221129174218151](D:\文档\学习笔记\学习疑问.assets\image-20221129174218151.png)

![image-20221129203014342](D:\文档\学习笔记\学习疑问.assets\image-20221129203014342.png)

### 分布式事务的执行流程

1、TM开启分布式事务(TM向TC注册全局事务记录)。

2、换业务场景，编排数据库，服务等事务内资源（RM向TC汇报资源准备状态）。

3、TM结束分布式事务，事务一阶段结束（TM通知TC提交/回滚分布式事务）。

4、TC汇总事务信息，决定分布式事务是提交还是回滚。

5、TC通知所有RM提交/回滚资源，事务二阶段结束。



## 13、Redis分布式锁和Zookeeper分布式锁有什么区别？

* 机制不同：redis分布式锁是基于键值对设立的，类似于Set集合，利用Set的去重性，使得同一资源只能有一个用户获得。同时Redis分布式锁需要配合luo脚本做到原子性更新。而zookeeper是类似于监听器机制实现的分布式锁。
* 死锁解决方案不同：redis是通过设置过期时间来减少死锁带来损害，一段时间内自动放弃锁的持有权。而zookeeper是基于会话有效期来解决死锁问题，当会话断开时就会自动释放对锁的持有权。
* 在集群模式下使用分布式锁，zookeeper比redis稳定，而性能没有redis好（redis是将数据存储在内存中）。为什么zookeeper更加稳定？因为zookeeper采用的是2PC一致性协议，保障了一致性。



## 14、Paxos算法是什么？详细说说？

### Basic Paxos

**三种角色**

1、Proposer：提议者，负责提出提案。

2、Acceptor：决策者，参与决策。

3、Learner：不参与决策，从其他角色学习最新达成一致的提案。

**两个阶段**

1、Prepare阶段：Proposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。

2、Accept阶段：Proposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。

**承诺和应答**

1、每个Proposer进行提案之前需要创建一个全局唯一且递增的proposal id，提案时携带这个id。

2、Acceptor收到Proposer的prepare请求后，对这个请求作出承诺，不再接受id小于等于这个请求的其他prepare请求，不再接收id小于这个请求的其他accept请求。

3、Prepare阶段应答：返回当前Acceptor已经Accept过的提案的id和val。

**问题**

1、极端情况下会形成活锁。

2、决议的形成至少需要两次网络请求，且一次决议只能确定一个值。

### Multi Paxos

**改进**

1、针对每一个要确定的值，运行一次Paxos算法实例（Instance），形成决议。每一个Paxos实例使用唯一的Instance ID标识。

2、在所有Proposers中选举一个Leader，由Leader唯一地提交Proposal给Acceptors进行表决。这样没有Proposer竞争，解决了活锁问题。在系统中仅有一个Leader进行Value提交的情况下，Prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。



## 15、缓存穿透、缓存击穿、缓存雪崩？

穿透：访问的key并不存在，缓存无法命中，流量达到数据库上。

击穿：访问的key过期了，有大量针对这个key的流量同时打过来。

雪崩：短时间内大量的key过期，针对这些key有大量的请求打过来。



## 16、负载均衡算法了解哪些？

一致性哈希算法

随机算法

轮询算法



## 17、BASE理论是什么？

**BA**：基本可用，保证数据的可用性。任何请求都会有响应（即使是失败的响应）。

**S**：软状态，软状态和硬状态相对，是指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据传输的过程中存在延时。

**E**：最终一致性，强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致性，而不需要实时保证系统数据的强一致性。



## 18、Raft协议是什么？

这篇文章还不错：https://zhuanlan.zhihu.com/p/488916891

# Java基础

## 1、Java里HashMap长度为什么是2的次幂？

* 原理是key%n == key&(n-1)
* 如果长度是2的次幂的话，可以让数据更散列更均匀，能够更充分的利用数组空间。原因是通过key的hashcode计算hash表中下标时要使用(n-1)&code，其中n是哈希表长度，code是hashcode，如果是2,的次幂的话，n-1的值中低位全部为1，进行&运算的散列更均匀。
* 方便操作，如果长度都为2的次幂的话，扩容迁移的时候不需要再重新通过哈希定位新的位置。
* 通过右移16位异或的方式减少哈希冲突：hash=h^(h>>>16)



## 2、HashMap中链表达到一定长度后为什么要变为红黑树？何时会将链表结构改成红黑树？

​	红黑树的查询效率高，能够提升效率。还能一定程度上缓解DDos攻击，当攻击者发送大量相同hash值的对象，往hashMap中存放，如果使用链表，会造成性能直线下降，改成红黑树结构，能够一定程度上抵御这种攻击。

​	当链表长度达到8时，当hash表数组的长度没有达到64时，会先尝试扩容hash表，因为扩容之后原来一个链表上的元素会分散到其他节点上。当hash表数组长度达到64时，就会将链表改为红黑树结构。

​	当红黑树长度小于6时，会将红黑树结构还原为链表。



# 并发

## 1、为什么要使用线程池？

* 减少开销，提高效率。如果有并发执行的需求，不使用线程池的话需要频繁创建和销毁线程，这些操作也需要开销。
* 便于管理。线程是稀缺资源，不能够无限制的创建，使用线程池能够控制创建线程的数量，同时可以进行统一的分配，调优和监控。



## 2、volatile关键字有什么作用？应用上对volatile的应用举例？

​	volatile关键字可以解决可读性、有序性问题。两阶段终止时，如果没有指定判断的变量为volatile，则有可能造成可读性问题。



## 3、什么是指令重排序？指令重排序会造成什么影响？

指令重排序分为：编译器重排序、CPU重排序、内存重排序。

**我的回答**：**编译器重排序**是指编译器在将高级语言编译成机器代码时，可能会对程序所做的优化，将一些顺序执行的指令重新排序。	**CPU重排序**：这其中也有CPU执行指令的流水线模型这个因素的影响，CPU将一条机器语言指令的执行又拆分成了很多小步骤，比如：取指、译码、执行、访存、写回，不同的指令可能某些小步骤的执行可能会有冲突，所以编译器会调整指令的顺序（在允许执行的情况下）。

**我的回答**：指令重排序并发场景下会造成可读性问题。



## 4、什么是Monitor？

​	Monitor被翻译为监视器或管程，使用synchronized给对象上锁之后，这个对象的对象头（Mark Word）中就会包含指向一个Monitor的指针（其实就是Monitor的内存地址），所以Monitor充当的其实是一个锁结构的角色。其中有三个主要组成部分：wait set（等待集合，用于存放在此对象上等待条件变量的对象）、entry list（阻塞队列，在阻塞队列中的线程相互竞争获取锁的权利）、owner（当前锁的持有者）。



## 5、什么是锁升级？

​	几个重要概念：轻量级锁、重量级锁、偏向锁。

### 轻量级锁

​	**特点**：不涉及Monitor。

​	**使用场景**是对象有多个使用者，但是这些使用者的使用时间是错开的，此时可以使用轻量级锁，避免开销过大。

​	**实现原理**

* 在每个线程的栈帧中维护锁记录结构，这个锁记录主要有两个重要组成部分：对象地址、锁记录地址（包含锁状态，最低两位是00），加轻量级锁时，会将锁记录地址和对象头中的Mark Word进行cas操作，cas成功则说明轻量级锁加锁成功；否则加锁失败，有两种情况：一个是当前对象锁已经被其他线程持有了，接下来将会进行锁膨胀（锁升级），二是当前对象锁被当前线程持有，说明发生了锁的重入，会在当前线程的栈帧中再生成一条锁记录。
* 解锁时如果锁记录的记录地址处为null，说明此记录为一条重入记录，这时重置锁记录（意思是找到下一个锁记录）；如果不为null，则再次使用cas和对象的Mark Word交换，如果交换失败，说明发生了锁膨胀，则进入重量级锁的解锁流程。

### 重量级锁

​	即使用Monitor，在使用重量级锁的情况下，内存中的结构是这样的：线程对应的栈帧中的锁记录指向对象，对象头中的Mark Word指向Monitor对象，而Monitor中的owner属性指向线程（锁记录？）。

### 偏向锁

​	在某些情况下，可能大部分时间里都只有一个线程反复给一个对象加锁，这时候如果使用轻量锁，每一次加锁过程都需要CAS操作，比较浪费，这时候就引出来了偏向锁，严格来说偏向锁并没有加上锁，只是在对象的Mark Word加上了线程标识，表明当前有线程正在使用。

​	偏向锁的撤销情况：

* 调用了对象的hash code方法时，会撤销掉当前对象上的偏向锁，因为hash code是存储在对象头中的Mark Word中的，使用轻量锁时，hash code通过CAS保存到线程锁记录中；使用重量锁时，hash code保存在Monitor中。
* 有其他线程加了偏向锁，当前线程检查到其他线程加了偏向锁，会将偏向锁升级为轻量级锁。
* 调用wait/notify会升级为重量级锁，只有重量级锁才支持wait/notify。



## 6、什么是可见性、有序性、原子性？怎么保证这些特性？

​	可见性：在多线程并发的场景下，由于CPU的结构，多个线程并行执行的时候会使用独立的缓存，有可能线程1对内存中的某个数据进行了修改，由于线程2将内存这个数据的值读取到了自己的缓存中，所以线程2后续使用的时候读到的是缓存中的数据，并不是被修改的在内存中的最新数据，这就造成了数据不可见的问题。

​	有序性：jvm可以在不影响程序正确性的情况下，对指令进行重排序，详见第三个问题。在多线程并行的情况下，有可能造成程序执行结果不符合预期。

​	原子性：高级语言层面的指令在实际执行的时候可能分为多条机器指令，这些机器指令应该作为一个整体来执行，而现实情况是在执行这一系列的机器指令时，由于调度机制，可能会切换到别的线程执行，使程序的运行结果出问题。

​	使用volatile可以解决可见性、有序性问题，但无法解决原子性问题。使用synchronized关键字可以解决原子性问题。



## 7、volatile是如何保证可见性、原子性的？

​	**通过内存读写屏障来保证可见性、原子性**。使用volatile修饰的变量，在读取操作时会在读取指令之前加上读屏障，读屏障保证：读屏障会从内存读取数据，所以使用volatile的变量能够保证可见性，并且保证在读屏障之后的指令不会重排序到屏障之前；在写操作时，会在写操作指令之后加上写屏障，写屏障保证写屏障之前的指令不能重排序到写屏障之后，并且保证在写屏障之前的对共享变量的改动，都同步到内存中。



## 8、内存屏障如何实现？

​	通过插入特定的内存屏障指令来实现内存屏障。

​	内存屏障指令又做了什么呢？首先明白两个东西

* Store Buffer：当一个CPU修改处于共享状态的缓存行时，需要通知其他正在共享这个缓存行的CPU，这个缓存行失效了，收到所有共享这个缓存行的CPU的大幅后，才能修改内存中的内容。从通知到收到答复肯定不是瞬间就完成的，所以这里会有个等待时间，这段时间里CPU没有执行任何指令，浪费了时间。作为改进，引入StoreBuffer，变为异步修改，当CPU要修改一个共享状态的缓存行时，向其他CPU发送通知，然后将修改后的缓存行内容放入StoreBuffer中，然后修改缓存行的CPU可以执行其他任务，等到其他CPU发送通知之后，再异步的将StoreBuffer的内容写入内存中。
* Invalid Queue：当CPU收到缓存invalid信息时，将这个信息先存入invalid queue，然后再异步的处理。（有点类似于消息队列？）

​	

​	接着需要知道几个指令：

* sfence：写屏障，使屏障之前的写操作对于屏障之后的操作是可见的。具体实现可以是将StoreBuffer中的所有修改的缓存行全部刷新至主存，也就是浪费等待回复的时间也要确保内容写入主存中。
* lfence：读屏障，从主存中重新读取内容到缓存，保证屏障之后读取缓存内容读取的是主存中最新的内容。
* mfence：全屏障，具有读和写屏障的功能，也就是要将StoreBuffer的内容刷新到主存中，也要从主存中重新读取内容到缓存。



## 9、JMM是什么？

​	java内存模型，是一种抽象的规则或者说规范，并不是实际存在的模型，java内存模型规范了JVM如何提供按序禁用缓存和编译优化的方法。也就是说，对于不同的JVM实现，都应该遵守这些规范，例如volatile关键字，如果用户使用了volatile关键字，虚拟机得要提供相应的功能：内存屏障。

​	JMM，java memory model，在不同硬件生产商和不同操作系统下，内存的访问操作有一定的差异，可能会造成相同的代码运行在不同的系统上会出现各种问题。java内存模型屏蔽掉各种硬件和操作系统的内存访问差异，以实现java程序在各种平台下都能达到一致的并发效果。



## 10、什么是happens-before原则？为什么需要happens-before原则？

​	happens-before原则表示的是前一个操作的结果对于后续操作的结果是可见的。可以认为在 JMM 中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作必须要存在happens-before关系。这两个操作可以是同一个线程，也可以是不同的线程。比如代码中前面的指令和后面的指令就满足这种关系。

​	六个规则：

* 程序的顺序性规则：程序顺序执行，前面的操作happens-before于后续的任意操作。也就是说假如当前的操作修改了变量值，那么后续的操作都能看到这个结果。
* volatile变量规则：对一个volatile变量的写操作，happens-before于后续对这个变量的读操作。我的理解是在时间上，当前对volatile变量进行了写操作，写操作的结果对后续读这个volatile变量的操作是可见的，这条规则主要是为了第三条规则做铺垫。
* 传递性：如果A happens-before B ， B happens-before C ，那么 A happens-before C。

~~~java
int x = 0;
volatile boolean flag = false;
public void fun1(){
    x = 10; //操作A
    flag = true; //操作B
}
public void fun2(){
    if(flag){ //操作C
        System.out.println(x); //操作D
    }
}
~~~

​	以上述程序为例，如果两个线程分别执行fun1和fun2方法，操作A  happens-before  操作B（程序的顺序性），如果fun2中操作C的执行晚于操作B，则符合volatile变量规则，即操作B  happens-before  操作C，由于传递性的存在，所以操作A  happens-before  操作C，即操作A的结果对于操作C以及后续的所有操作都是可见的，那么操作D输出的就应该是10。

* 管程中锁的规则：对一个锁的解锁 happens-before 于后续对这个锁的加锁。假设有两个线程：线程A和线程B，对同一个对象进行synchronized操作，如果线程A获得了对象锁，那么线程B会被阻塞住，直到线程A执行完毕，释放了这个对象的锁，线程B才能对这个对象加锁，往下执行。在上述过程中，线程A在同步代码块中对共享变量的写操作对于线程B获取到锁之后执行的操作是可见的。
* 线程start()规则：线程A启动子线程B之后，子线程B能够看到线程A在启动线程B之前的操作。在线程A调用线程B的start之前对共享变量进行的写操作，对于线程B启动后的操作都是可见的。
* 线程join()规则：线程A等待线程B完成（调用线程B的join方法），当线程B完成后，线程A能够看到线程B对于共享变量的修改。



**为什么需要？**

​	happens-before原则是JMM规范中很重要的一部分，目的就是为了解决并发程序执行中会出现的可见性、有序性问题，遵循了happens-before原则，可以很大程度上避免出现这些问题。试想一下，如果不遵循happens-before原则，程序会出现什么样的情况？程序顺序执行时，前面的操作对于后面的操作可能不可见？那程序执行不就有问题了吗？



## 11、什么是AQS？设计AQS需要考虑什么？

​	全称是 AbstractQueuedSynchronizer，是阻塞式锁和相关的同步器工具的框架 。也就是jdk中定义好的一个同步器模板，通过这个模板，开发人员可以很方便的实现自己需要的同步器。

​	需要考虑State状态、阻塞队列、阻塞方式等。

* state状态可以设计成独占的或者共享的，例如读写锁的设计，高16位表示读锁，低16位表示写锁。state字段使用volatile保证可见性和有序性，使用cas保证原子性，还需要考虑字段的大小，通常使用32位int来维护同步状态，因为使用long类型在很多平台下测试结果并不理想。
* 阻塞恢复设计，使用park和unpark来进行阻塞和恢复，原因有几点：
  * 先unpark，再park，线程能够感知到，而早期使用的suspend和resume方法是做不到的。
  * park和unpark是针对线程的，控制粒度更精细，而wait和notify则是针对同步器（锁对象）的，必须要先获得锁才能进行wait和notify。
  * park线程可以通过interrupt打断。
* 队列设计，采用FIFO队列，不支持优先级队列，有头节点和尾节点指针，维护一个哑元节点，便于操作。



## 12、并发死链问题是什么？如何解决？

​	在jdk7中，HashMap在多线程并发环境下进行扩容时，可能会出现死循环的情况，这种情况叫做并发死链问题。具体来说，jdk7中造成死链问题的主要原因是扩容后的哈希表加入节点的顺序是将新的节点插入到链表的头部，这样会造成死循环问题。出现死链主要原因还是在并发场景下使用了非线程安全的Map集合。



## 13、Synchronized和ReEntryLock的区别是什么？

​	synchronized：

* 是java的关键字，自动获取和释放锁。
* 同步代码块中出现异常时，由jvm处理并释放锁。
* 阻塞式获取锁。
* 可重入、不可中断、非公平。



​	reentrylock：

* 是一个类，必须手动获取和释放锁。
* 出现异常时，必须使用try语句抓捕异常，在finally中进行锁的释放。
* 使用tryLock()可以尝试获取锁，一定时间内没有获取到，则放弃获取锁。
* 可重入、可中断、可公平。



## 14、如何解决缓存和数据库不一致问题？

​	**几种策略：**

* 更新数据库，也更新缓存

  ​	问题：两个更新是不同的操作，有可能出现并发写问题。如果有两个线程更新一个目标，假设线程A先更新了数据库，还没来得及更新缓存，这时候线程B也更新了数据库，同时更新了缓存，最后线程A才将缓存更新。按照理想的情况来说，最终数据库中的值是线程B更新的值，所以缓存中也应该是线程B更新的值，但最后缓存中的值却是线程A更新的值，出现脏读现象。

​	（补充一个图片更好理解）

* 删除缓存，更新数据库

  ​	问题：会出现并发读写问题。假设有一个写线程A和一个读线程B，在线程A删除缓存后，更新数据库之前，线程B要读取这个目标，先查询缓存，缓存未命中，从数据库中查找出来，并更新缓存，线程B执行完上述操作之后，线程A才更新数据库中的值，那么线程B此前读取出来的数据就是旧的数据，导致了脏读问题。

  ​	如何优化？使用双删策略，也就是在执行完删除缓存、更新性能数据库操作之后，延迟一段时间再删一遍缓存。（这个延迟时间的控制需要根据自己的业务调整）

  ​	如果采用了MySQL读写分离架构怎么办？在读写分离下，写线程对主数据库操作，读线程对从数据库操作，如果还是按照一般情况的双删策略制定延迟时间，则仍然会出现脏数据问题，因为第二次删除的时候，主服务器更新的数据还没有同步到从服务器上，所以延迟策略需要考虑上主从同步的时间，就可以解决脏数据问题了。

* 更新数据库，删除缓存

  ​	问题：会出现并发读写问题。假设线程A执行更新操作，线程B执行读操作。**情况一：**线程A更新完数据库，还没有更新缓存时，线程B执行读取操作，此时读到的数据是脏数据。**情况二：**线程B查询时缓存失效，则线程B需要读取数据库、更新缓存，这是两步操作，假设在线程B读取完数据库，更新缓存之前，线程A执行更新数据库，删除缓存操作，接着线程B才将刚刚读取到的数据写入缓存中，那么此后读取缓存的内容都是脏数据。

  ​	如何不让第二种情况出现？也是采取延迟双删策略。



​	选哪个策略？通常情况下，采用更新数据库，再删除缓存的策略，因为虽然此策略也会造成不一致的问题，但是两种不一致的情况中，第一种情况造成的影响有限，因为只有在线程A更新数据库和删除缓存之间进行读操作的线程才会出现脏读现象。第二种情况出现的概率很小，要基于两个时间同时发生：缓存失效、其他线程正在更新数据。

​	

​	**如果要强一致性呢？**无法保障，因为cap理论中一致性、高可用性、分区容错性无法同时满足，为了达到高可用的目的，就必须忍受不一致情况的发生，无法做到强一致性。



## 15、ConcurrentHashMap

问题：什么是ConcurrentHashMap？它是如何解决并发读写问题的？为什么它的get方法不需要加锁，能否分析分析？

​	ConcurrentHashMap是JUC包下的线程安全的HashMap，并且并发性能好。

​	通过很多的cas操作解决并发写入问题。

​	因为ConcurrentHashMap的属性都有volatile关键字，保证了其他线程get时是可见的。

问题：ConcurrentHashMap的put流程？扩容流程？

​	jdk8中：

* 首先会计算出key的hashcode，用于定位key在node数组中的下标；接着进入一个死循环，先检查node数组是否初始化，懒惰初始化；检查对应的node链表是否为空，为空就cas将当前key-value作为头结点；不为空则检查是否扩容中，通过node节点的hash值判断是否进入扩容流程，如果是扩容流程，node头结点的hash值会做特殊修改，如果是扩容中，当前线程帮忙扩容；以上情况都没有发生的话，需要遍历node链表寻找key对应的节点是否存在，先将头结点上锁（synchronized），然后需要确认头结点是否发生了变化（有可能在上锁过程中node数组中的头节点发生了变化），接着判断节点是链表类型还是红黑树类型，分别走不同的遍历流程，如果key对应的节点存在，则覆盖值，不存在则增加节点。
* 扩容时会先创建一个新的node数组，放在nextTable属性中，然后从后往前遍历原node数组，如果当前node链表已经扩容完成，则在这个位置添加一个ForwardingNode头结点，接着处理下一个元素。

​	jdk7中：

* 首先通过key计算出hashcode，然后通过hashcode计算出segment数组的下标，接着检查对应元素是否为null，为null则需要进入ensureSegment()方法执行，在此方法中用cas方式保证创建segment的安全性。有了segment之后，通过segment的put方法添加节点：首先会使用tryLock()尝试加锁，如果加锁失败会进入一个方法中执行，会不断尝试加锁，并且在尝试过程中，会将对应的node节点创建出来；加锁成功后，就是定位元素下标，添加到node链表上，由于已经加锁，所以不需要考虑线程安全性，特别需要注意的是jdk7中添加到链表上的顺序是加到头结点，而不是加到链表尾部，这也是造成普通hashMap出现并发死链的原因。

### JDK8

#### 重要属性

~~~java
// 默认为 0
// 当初始化时, 为 -1
// 当扩容时, 为 -(1 + 扩容线程数)
// 当初始化或扩容完成后，为 下一次的扩容的阈值大小
private transient volatile int sizeCtl;

// 整个 ConcurrentHashMap 就是一个 Node[]
static class Node<K,V> implements Map.Entry<K,V> {}

// hash 表
transient volatile Node<K,V>[] table;

// 扩容时的 新 hash 表
private transient volatile Node<K,V>[] nextTable;

// 基础的数量
private transient volatile long baseCount;

// 用于操作CounterCell数组的锁
private transient volatile int cellsBusy;

// 并发情况下用于计算操作的数组
private transient volatile CounterCell[] counterCells;

// 扩容时如果某个 bin 迁移完毕, 用 ForwardingNode 作为旧 table bin 的头结点
static final class ForwardingNode<K,V> extends Node<K,V> {}

// 用在 compute 以及 computeIfAbsent 时, 用来占位, 计算完成后替换为普通 Node
static final class ReservationNode<K,V> extends Node<K,V> {}

// 作为 treebin 的头节点, 存储 root 和 first
static final class TreeBin<K,V> extends Node<K,V> {}

// 作为 treebin 的节点, 存储 parent, left, right
static final class TreeNode<K,V> extends Node<K,V> {}
~~~

#### get流程

~~~java
public V get(Object key) {
    Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek;
    // spread 方法能确保返回结果是正数
    int h = spread(key.hashCode());
    if ((tab = table) != null && (n = tab.length) > 0 &&
        (e = tabAt(tab, (n - 1) & h)) != null) {
        // 如果头结点已经是要查找的 key
        if ((eh = e.hash) == h) {
            if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                return e.val;
        }
        // hash 为负数表示该 bin 在扩容中或是 treebin, 这时调用 find 方法来查找
        else if (eh < 0)
            return (p = e.find(h, key)) != null ? p.val : null;
        // 正常遍历链表, 用 equals 比较
        while ((e = e.next) != null) {
            if (e.hash == h &&
                ((ek = e.key) == key || (ek != null && key.equals(ek))))
                return e.val;
        }
    }
    return null;
}
~~~

#### put流程

~~~java
public V put(K key, V value) {
    return putVal(key, value, false);
}

final V putVal(K key, V value, boolean onlyIfAbsent) {
    if (key == null || value == null) throw new NullPointerException();
    // 其中 spread 方法会综合高位低位, 具有更好的 hash 性
    int hash = spread(key.hashCode());
    //用于统计节点数量
    int binCount = 0;
    for (Node<K,V>[] tab = table;;) {
        // f 是链表头节点
        // fh 是链表头结点的 hash
        // i 是链表在 table 中的下标
        Node<K,V> f; int n, i, fh;
        // 要创建 table
        if (tab == null || (n = tab.length) == 0)
            // 初始化 table 使用了 cas, 无需 synchronized 创建成功, 进入下一轮循环
            tab = initTable();
        // 要创建链表头节点
        else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
            // 添加链表头使用了 cas, 无需 synchronized
            if (casTabAt(tab, i, null,
                         new Node<K,V>(hash, key, value, null)))
                break;
        }
        // 帮忙扩容
        else if ((fh = f.hash) == MOVED)
            // 帮忙之后, 进入下一轮循环
            tab = helpTransfer(tab, f);
        else {
            V oldVal = null;
            // 锁住链表头节点
            synchronized (f) {
                // 再次确认链表头节点没有被移动
                if (tabAt(tab, i) == f) {
                    // 链表
                    if (fh >= 0) {
                        //链表数量从头结点开始计数，头结点数量为1
                        binCount = 1;
                        // 遍历链表
                        for (Node<K,V> e = f;; ++binCount) {
                            K ek;
                            // 找到相同的 key
                            if (e.hash == hash &&
                                ((ek = e.key) == key ||
                                 (ek != null && key.equals(ek)))) {
                                oldVal = e.val;
                                // 更新
                                if (!onlyIfAbsent)
                                    e.val = value;
                                break;
                            }
                            Node<K,V> pred = e;
                            // 已经是最后的节点了, 新增 Node, 追加至链表尾
                            if ((e = e.next) == null) {
                                pred.next = new Node<K,V>(hash, key,
                                                          value, null);
                                break;
                            }
                        }
                    }
                    // 红黑树
                    else if (f instanceof TreeBin) {
                        Node<K,V> p;
                        binCount = 2;
                        // putTreeVal 会看 key 是否已经在树中, 是, 则返回对应的 TreeNode
                        if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                              value)) != null) {
                            oldVal = p.val;
                            if (!onlyIfAbsent)
                                p.val = value;
                        }
                    }
                }
                // 释放链表头节点的锁
            }
            
            if (binCount != 0) { 
                if (binCount >= TREEIFY_THRESHOLD)
                    // 如果链表长度 >= 树化阈值(8), 进行链表转为红黑树
                    treeifyBin(tab, i);
                if (oldVal != null)
                    return oldVal;
                break;
            }
        }
    }
    // 增加 size 计数
    addCount(1L, binCount);
    return null; 
}
~~~

大概的流程是：进入循环，判断hash表有没有初始化，如果没有初始化则进行初始化；否则判断hash表中对应key位置的头结点是否创建了，如果没有创建，则通过cas创建，成功则退出循环，失败则继续循环；否则判断头结点是否处于扩容状态，如果是扩容状态，则帮忙进行扩容；如果不是以上情况，则开始遍历节点链表，需要先给头结点使用synchronized锁上，然后再遍历查找是否有对应key的节点存在，存在就根据onlyIfAbsent属性判断是否要替换值，然后退出死循环，不存在的话，就在链表尾部新增一个节点。

#### 初始化

~~~java
private final Node<K,V>[] initTable() {
    Node<K,V>[] tab; int sc;
    while ((tab = table) == null || tab.length == 0) {
        if ((sc = sizeCtl) < 0)
            Thread.yield();
        // 尝试将 sizeCtl 设置为 -1（表示初始化 table）
        else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
            // 获得锁, 创建 table, 这时其它线程会在 while() 循环中 yield 直至 table 创建
            try {
                if ((tab = table) == null || tab.length == 0) {
                    int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                    Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                    table = tab = nt;
                    sc = n - (n >>> 2);
                }
            } finally {
                sizeCtl = sc;
            }
            break;
        }
    }
    return tab; 
}
~~~

#### addCount流程

~~~java
private final void addCount(long x, int check) {
    CounterCell[] as; long b, s;
    //如果增加大小出现了冲突，就使用CounterCells来存放数量
    if ((as = counterCells) != null ||
        !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) {
        CounterCell a; long v; int m;
        boolean uncontended = true;
        //如果CounterCells还没初始化，或者长度为0，或者当前线程应该更新的那个元素为null，或者cas更新元素失败，就另外执行
        if (as == null || (m = as.length - 1) < 0 ||
            (a = as[ThreadLocalRandom.getProbe() & m]) == null ||
            !(uncontended =
              U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) {
            fullAddCount(x, uncontended);
            //为什么这里要return呢？如果有一个步骤不对的话，就不需要扩容了吗
            return;
        }
        if (check <= 1)
            return;
        s = sumCount();
    }
    if (check >= 0) {
        Node<K,V>[] tab, nt; int n, sc;
        while (s >= (long)(sc = sizeCtl) && (tab = table) != null &&
               (n = tab.length) < MAXIMUM_CAPACITY) {
            int rs = resizeStamp(n);
            if (sc < 0) {
                if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 ||
                    sc == rs + MAX_RESIZERS || (nt = nextTable) == null ||
                    transferIndex <= 0)
                    break;
                if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1))
                    transfer(tab, nt);
            }
            else if (U.compareAndSwapInt(this, SIZECTL, sc,
                                         (rs << RESIZE_STAMP_SHIFT) + 2))
                transfer(tab, null);
            s = sumCount();
        }
    }
}

//给CounterCells数组初始化，创建对应下标的元素，最终完成加操作的方法
private final void fullAddCount(long x, boolean wasUncontended) {
    int h;
    if ((h = ThreadLocalRandom.getProbe()) == 0) {
        ThreadLocalRandom.localInit();      // force initialization
        h = ThreadLocalRandom.getProbe();
        wasUncontended = true;
    }
    boolean collide = false;                // True if last slot nonempty
    for (;;) {
        CounterCell[] as; CounterCell a; int n; long v;
        if ((as = counterCells) != null && (n = as.length) > 0) {
            if ((a = as[(n - 1) & h]) == null) {
                if (cellsBusy == 0) {            // Try to attach new Cell
                    CounterCell r = new CounterCell(x); // Optimistic create
                    if (cellsBusy == 0 &&
                        U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                        boolean created = false;
                        try {               // Recheck under lock
                            CounterCell[] rs; int m, j;
                            if ((rs = counterCells) != null &&
                                (m = rs.length) > 0 &&
                                rs[j = (m - 1) & h] == null) {
                                rs[j] = r;
                                created = true;
                            }
                        } finally {
                            cellsBusy = 0;
                        }
                        if (created)
                            break;
                        continue;           // Slot is now non-empty
                    }
                }
                collide = false;
            }
            else if (!wasUncontended)       // CAS already known to fail
                wasUncontended = true;      // Continue after rehash
            else if (U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))
                break;
            else if (counterCells != as || n >= NCPU)
                collide = false;            // At max size or stale
            else if (!collide)
                collide = true;
            else if (cellsBusy == 0 &&
                     U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                try {
                    if (counterCells == as) {// Expand table unless stale
                        CounterCell[] rs = new CounterCell[n << 1];
                        for (int i = 0; i < n; ++i)
                            rs[i] = as[i];
                        counterCells = rs;
                    }
                } finally {
                    cellsBusy = 0;
                }
                collide = false;
                continue;                   // Retry with expanded table
            }
            h = ThreadLocalRandom.advanceProbe(h);
        }
        else if (cellsBusy == 0 && counterCells == as &&
                 U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
            boolean init = false;
            try {                           // Initialize table
                if (counterCells == as) {
                    CounterCell[] rs = new CounterCell[2];
                    rs[h & 1] = new CounterCell(x);
                    counterCells = rs;
                    init = true;
                }
            } finally {
                cellsBusy = 0;
            }
            if (init)
                break;
        }
        else if (U.compareAndSwapLong(this, BASECOUNT, v = baseCount, v + x))
            break;                          // Fall back on using base
    }
}
~~~

fullAddCount整体流程：检查counterCells数组是否为null

* 不为null
  * 检查当前线程应该操作的那个cell元素为null，检查cellsbusy是否为0（表示空闲，没有其他线程正在修改counterCells数组），为0则创建一个CounterCell元素，并初始化其值为要更新的值，然后再次检查cellsbusy是否为0，如果为0，使用cas将cellsbusy修改为1，然后再次检查counterCells数组以及对应下标的元素，确保没有被别的线程进行修改，再将对应下标处的元素修改为刚刚新创建的CounterCell元素，一切无误则退出循环。
  * 检查uncontended标识，如果之前已经尝试cas对应的cell元素失败的话，uncontended标识为false，则不必再次尝试cas，而是将uncontended改为true，等到rehash后再尝试cas。
  * 对应的cell元素不为null，则cas修改对应的cell的值，使其加上要增加的值，成功则退出循环。
  * cas失败，检查counterCells数组是否被修改过，如果修改过，则将collide标识修改为false，然后继续循环。
  * 检查collide标识，如果为false则改为true，然后继续循环，作用应该是再给一次遍历的机会。
  * 如果collide标识为true，则cas修改cellsBusy属性为1，对counterCells数组进行扩容。
* 为null，对cellsbusy属性进行cas加锁成功
* cellsbusy加锁失败，使用cas更改baseCount属性。

#### size计算流程

~~~java
public int size() {
    long n = sumCount();
    return ((n < 0L) ? 0 :
            (n > (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE :
            (int)n);
}

final long sumCount() {
    CounterCell[] as = counterCells; CounterCell a;
    // 将 baseCount 计数与所有 cell 计数累加
    long sum = baseCount;
    if (as != null) {
        for (int i = 0; i < as.length; ++i) {
            if ((a = as[i]) != null)
                sum += a.value;
        }
    }
    return sum;
}
~~~





### JDK7

#### 重要属性

~~~java
//寻找segment下标的掩码
final int segmentMask;

//定位segment下标的右移次数
final int segmentShift;

//segment数组
final Segment<K,V>[] segments;

transient Set<K> keySet;
transient Set<Map.Entry<K,V>> entrySet;
transient Collection<V> values;
~~~

#### 初始化

~~~java
public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) {
    if (!(loadFactor > 0) || initialCapacity < 0 || concurrencyLevel <= 0)
        throw new IllegalArgumentException();
    if (concurrencyLevel > MAX_SEGMENTS)
        concurrencyLevel = MAX_SEGMENTS;
    // ssize 必须是 2^n, 即 2, 4, 8, 16 ... 表示了 segments 数组的大小
    int sshift = 0;
    int ssize = 1;
    while (ssize < concurrencyLevel) {
        ++sshift;
        ssize <<= 1;
    }
    // segmentShift 默认是 32 - 4 = 28
    this.segmentShift = 32 - sshift;
    // segmentMask 默认是 15 即 0000 0000 0000 1111
    this.segmentMask = ssize - 1;
    if (initialCapacity > MAXIMUM_CAPACITY)
        initialCapacity = MAXIMUM_CAPACITY;
    int c = initialCapacity / ssize;
    if (c * ssize < initialCapacity)
        ++c;
    int cap = MIN_SEGMENT_TABLE_CAPACITY;
    while (cap < c)
        cap <<= 1;
    // 创建 segments and segments[0]
    Segment<K,V> s0 =
        new Segment<K,V>(loadFactor, (int)(cap * loadFactor),
                         (HashEntry<K,V>[])new HashEntry[cap]);
    Segment<K,V>[] ss = (Segment<K,V>[])new Segment[ssize];
    UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0]
    this.segments = ss; 
}
~~~

#### put流程

~~~java
public V put(K key, V value) {
    Segment<K,V> s;
    if (value == null)
        throw new NullPointerException();
    int hash = hash(key);
    int j = (hash >>> segmentShift) & segmentMask;
    if ((s = (Segment<K,V>)UNSAFE.getObject          // nonvolatile; recheck
         (segments, (j << SSHIFT) + SBASE)) == null) //  in ensureSegment
        s = ensureSegment(j);
    return s.put(key, hash, value, false);
}
//多重检查，使用cas创建对应下标的segment元素
private Segment<K,V> ensureSegment(int k) {
    final Segment<K,V>[] ss = this.segments;
    long u = (k << SSHIFT) + SBASE; // raw offset
    Segment<K,V> seg;
    if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u)) == null) {
        Segment<K,V> proto = ss[0]; // use segment 0 as prototype
        int cap = proto.table.length;
        float lf = proto.loadFactor;
        int threshold = (int)(cap * lf);
        HashEntry<K,V>[] tab = (HashEntry<K,V>[])new HashEntry[cap];
        if ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))
            == null) { // recheck
            Segment<K,V> s = new Segment<K,V>(lf, threshold, tab);
            while ((seg = (Segment<K,V>)UNSAFE.getObjectVolatile(ss, u))
                   == null) {
                if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s))
                    break;
            }
        }
    }
    return seg;
}
~~~

由于segment继承了ReentrantLock，所以其自身拥有锁的特性
~~~java
//segment元素的put方法
final V put(K key, int hash, V value, boolean onlyIfAbsent) {
    HashEntry<K,V> node = tryLock() ? null :
    scanAndLockForPut(key, hash, value);
    V oldValue;
    try {
        HashEntry<K,V>[] tab = table;
        int index = (tab.length - 1) & hash;
        HashEntry<K,V> first = entryAt(tab, index);
        for (HashEntry<K,V> e = first;;) {
            if (e != null) {
                K k;
                if ((k = e.key) == key ||
                    (e.hash == hash && key.equals(k))) {
                    oldValue = e.value;
                    if (!onlyIfAbsent) {
                        e.value = value;
                        ++modCount;
                    }
                    break;
                }
                e = e.next;
            }
            else {
                if (node != null)
                    node.setNext(first);
                else
                    node = new HashEntry<K,V>(hash, key, value, first);
                int c = count + 1;
                if (c > threshold && tab.length < MAXIMUM_CAPACITY)
                    rehash(node);
                else
                    setEntryAt(tab, index, node);
                ++modCount;
                count = c;
                oldValue = null;
                break;
            }
        }
    } finally {
        unlock();
    }
    return oldValue;
}
~~~

#### rehash流程

~~~java
private void rehash(HashEntry<K,V> node) {
    HashEntry<K,V>[] oldTable = table;
    int oldCapacity = oldTable.length;
    int newCapacity = oldCapacity << 1;
    threshold = (int)(newCapacity * loadFactor);
    HashEntry<K,V>[] newTable =
        (HashEntry<K,V>[]) new HashEntry[newCapacity];
    int sizeMask = newCapacity - 1;
    for (int i = 0; i < oldCapacity ; i++) {
        HashEntry<K,V> e = oldTable[i];
        if (e != null) {
            HashEntry<K,V> next = e.next;
            int idx = e.hash & sizeMask;
            if (next == null) // Single node on list
                newTable[idx] = e;
            else { // Reuse consecutive sequence at same slot
                HashEntry<K,V> lastRun = e;
                int lastIdx = idx;
                // 过一遍链表, 尽可能把 rehash 后 idx 不变的节点重用
                for (HashEntry<K,V> last = next;
                     last != null;
                     last = last.next) {
                    int k = last.hash & sizeMask;
                    if (k != lastIdx) {
                        lastIdx = k;
                        lastRun = last;
                    }
                }
                newTable[lastIdx] = lastRun;
                // 剩余节点需要新建
                for (HashEntry<K,V> p = e; p != lastRun; p = p.next) {
                    V v = p.value;
                    int h = p.hash;
                    int k = h & sizeMask;
                    HashEntry<K,V> n = newTable[k];
                    newTable[k] = new HashEntry<K,V>(h, p.key, v, n);
                }
            }
        }
    }
    // 扩容完成, 才加入新的节点
    int nodeIndex = node.hash & sizeMask; // add the new node
    node.setNext(newTable[nodeIndex]);
    newTable[nodeIndex] = node;
    
    // 替换为新的 HashEntry table
    table = newTable; 
}
~~~

#### get流程

~~~java
public V get(Object key) {
    Segment<K,V> s; // manually integrate access methods to reduce overhead
    HashEntry<K,V>[] tab;
    int h = hash(key);
    // u 为 segment 对象在数组中的偏移量
    long u = (((h >>> segmentShift) & segmentMask) << SSHIFT) + SBASE;
    // s 即为 segment
    if ((s = (Segment<K,V>)UNSAFE.getObjectVolatile(segments, u)) != null &&
        (tab = s.table) != null) {
        for (HashEntry<K,V> e = (HashEntry<K,V>) UNSAFE.getObjectVolatile
             (tab, ((long)(((tab.length - 1) & h)) << TSHIFT) + TBASE);
             e != null; e = e.next) {
            K k;
            if ((k = e.key) == key || (e.hash == h && key.equals(k)))
                return e.value;
        }
    }
    return null; 
}
~~~

#### size计算流程

- 计算元素个数前，先不加锁计算两次，如果前后两次结果如一样，认为个数正确返回 
- 如果不一样，进行重试，重试次数超过 3，将所有 segment 锁住，重新计算个数返回

~~~java
public int size() {
    // Try a few times to get accurate count. On failure due to
    // continuous async changes in table, resort to locking.
    final Segment<K,V>[] segments = this.segments;
    int size;
    boolean overflow; // true if size overflows 32 bits
    long sum; // sum of modCounts
    long last = 0L; // previous sum
    int retries = -1; // first iteration isn't retry
    try {
        for (;;) {
            if (retries++ == RETRIES_BEFORE_LOCK) {
                // 超过重试次数, 需要创建所有 segment 并加锁
                for (int j = 0; j < segments.length; ++j)
                    ensureSegment(j).lock(); // force creation
            }
            sum = 0L;
            size = 0;
            overflow = false;
            for (int j = 0; j < segments.length; ++j) {
                Segment<K,V> seg = segmentAt(segments, j);
                if (seg != null) {
                    sum += seg.modCount;
                    int c = seg.count;
                    if (c < 0 || (size += c) < 0)
                        overflow = true;
                }
            }
            if (sum == last)
                break;
            last = sum;
        }
    } finally {
        if (retries > RETRIES_BEFORE_LOCK) {
            for (int j = 0; j < segments.length; ++j)
                segmentAt(segments, j).unlock();
        }
    }
    return overflow ? Integer.MAX_VALUE : size; 
}
~~~



### 总结

JDK8和JDK7中ConcurrentHashMap的不同点：

* JDK8中使用锁的方式是cas方式，而JDK7使用锁是ReentrantLock。
* 维护hash表的结构不同，jdk8中维护两个hash表，一个是当前存放值的，一个是扩容使用的；jdk7中维护的是一个segment数组，而每个segment中维护一个hash表。
* 计算元素数量方式不同，jdk8中使用BaseCount + CounterCells数组的方式来计算：当没有竞争时，直接cas修改baseCount属性，出现竞争时，不同的线程cas修改CounterCells数组中不同的元素，统计个数时，需要计算baseCount+CounterCells数组中各元素的值；jdk7中使用的方法是多次计算，只有当前计算的值等于前一次计算的值的时候才算成功计算，否则就继续计算，重试次数超过3次就将所有的segment锁上，再进行计算。



## 16、ThreadLocal是什么？有什么用？它是如何实现的？

​	ThreadLocal的作用是维护一个线程执行时所需要的参数，使用它能够避免线程安全问题，对线程的访问起到了隔离的作用。

​	实际的应用：Spring的注解*@Transactional*就使用到了ThreadLocal，因为使用了这个注解的方法需要保证事务，即使进行了多层的方法调用，正在执行的方法当中也要能够获得同一个Connection对象，Spring的做法就是将Connection对象存入了ThreadLocal中，这样一个线程在执行的过程中所使用到的Connection对象就是同一个。

​	实现：ThreadLocal作为一个全局变量存在，而每个线程中都有自己私有的成员变量ThreadLocalMap，类似于一个Map，存储线程自己的变量时，实质上就是以ThreadLocal对象引用为key，线程局部变量为value，存入到ThreadLocalMap中。

​	内存泄漏：ThreadLocalMap中的节点对象的key是以弱引用的形式存在的，就是为了避免当作为key的ThreadLocal应该被回收时，由于存在这些key（可能很多线程里都以这个ThreadLocal对象作为key）导致垃圾回收期无法回收ThreadLocal对象。但是这样仍然会出现内存泄漏的情况：Map中的value是以强引用的形式存在的，不主动将这个引用撤销掉的话，它是不会被垃圾回收期回收的。

​	还需要注意的点：如果是自己设计线程池的话，线程使用完，归还给线程池时，一定要将ThreadLocalMap清理掉，不然很有可能造成内存溢出问题。

### 线程中的重要属性

​	每个线程中都有这么一个属性，ThreadLocalMap

~~~java
//线程对象中的属性
ThreadLocal.ThreadLocalMap threadLocals = null;

//ThreadLocalMap是ThreadLocal的一个静态内部类
static class ThreadLocalMap {
    //map中存放键值对的节点，可以看到继承了弱引用
    static class Entry extends WeakReference<ThreadLocal<?>> {
        /** The value associated with this ThreadLocal. */
        Object value;

        Entry(ThreadLocal<?> k, Object v) {
            super(k);
            value = v;
        }
    }
    //节点数组
    private Entry[] table;
    private int size = 0;
    private int threshold; // Default to 0
}
~~~

### ThreadLocal的set流程

```java
public void set(T value) {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null)
        map.set(this, value);
    else
        createMap(t, value);
}
ThreadLocalMap getMap(Thread t) {
    return t.threadLocals;
}
void createMap(Thread t, T firstValue) {
    t.threadLocals = new ThreadLocalMap(this, firstValue);
}

//ThreadLocalMap的set方法，为方便阅读，放在此处
private void set(ThreadLocal<?> key, Object value) {

    // We don't use a fast path as with get() because it is at
    // least as common to use set() to create new entries as
    // it is to replace existing ones, in which case, a fast
    // path would fail more often than not.

    Entry[] tab = table;
    int len = tab.length;
    int i = key.threadLocalHashCode & (len-1);

    for (Entry e = tab[i];
         e != null;
         e = tab[i = nextIndex(i, len)]) {
        ThreadLocal<?> k = e.get();

        if (k == key) {
            e.value = value;
            return;
        }

        if (k == null) {
            replaceStaleEntry(key, value, i);
            return;
        }
    }

    tab[i] = new Entry(key, value);
    int sz = ++size;
    if (!cleanSomeSlots(i, sz) && sz >= threshold)
        rehash();
}
```

### ThreadLocal的get流程

~~~java
public T get() {
    Thread t = Thread.currentThread();
    ThreadLocalMap map = getMap(t);
    if (map != null) {
        ThreadLocalMap.Entry e = map.getEntry(this);
        if (e != null) {
            @SuppressWarnings("unchecked")
            T result = (T)e.value;
            return result;
        }
    }
    return setInitialValue();
}

//ThreadLocalMap中的方法
private Entry getEntry(ThreadLocal<?> key) {
    int i = key.threadLocalHashCode & (table.length - 1);
    Entry e = table[i];
    if (e != null && e.get() == key)
        return e;
    else
        return getEntryAfterMiss(key, i, e);
}
private Entry getEntryAfterMiss(ThreadLocal<?> key, int i, Entry e) {
    Entry[] tab = table;
    int len = tab.length;

    while (e != null) {
        ThreadLocal<?> k = e.get();
        if (k == key)
            return e;
        if (k == null)
            expungeStaleEntry(i);
        else
            i = nextIndex(i, len);
        e = tab[i];
    }
    return null;
}
~~~



## 17、unpark操作算是打扰了线程吗？会导致线程的interrupt状态为true吗？

不会导致interrupt状态为true。

~~~java
public static void main(String[] args) throws InterruptedException {
    Thread t1 = new Thread(() -> {
        LockSupport.park();
        System.out.println(Thread.interrupted());
    });

    t1.start();
    Thread.sleep(1000);
    LockSupport.unpark(t1);
}
~~~

![img](https://cdn.nlark.com/yuque/0/2023/png/33595836/1676433682243-6178dff5-5b9c-47b2-8923-bee7fe2ff186.png)



## 18、设计一个线程池需要考虑什么？jdk中有哪些线程池，举例说明？

### 设计线程池

1、任务队列。

* 增加任务和消费任务采用生产者消费者模式，需要加锁进行操作。
* 提供带超时时间的增加和消费方法。
* 增加任务时，如果队列满了，使用拒绝策略来拒绝增加。

2、线程集合。

* 使用惰性创建，使用时才创建核心线程，长时间没有任务执行时会自动结束线程。

3、核心线程数。

4、获取任务超时时间。

5、拒绝策略。

* 死等
* 带超时等待
* 让调用者放弃任务执行
* 让调用者抛出异常
* 让调用者自己执行任务

### 线程池状态

使用int属性记录线程池状态和线程数量，高三位为线程池状态。

![image-20230224104044912](D:\文档\学习笔记\学习疑问.assets\image-20230224104044912.png)

### 常见线程池

1、newFixedThreadPool：没有救急线程，核心线程数等于最大线程数，阻塞队列是无界的。适合任务量已知，相对耗时的任务。

2、newCacheThreadPool：没有核心线程，最大线程数是Integer.MAX_VALUE（救急线程最大数量），救急线程空闲生存时间是60s，使用SynchronousQueue，特点是没有容量，没有线程来取是放不进去的（那这个阻塞队列有啥用？）。适合任务数量比较密集，但每个任务执行时间比较短的情况。

3、newSingleThreadExector：线程数固定为1，阻塞队列为无界队列。和自己创建一个线程的区别：自己创建，如果出现异常，任务终止而没有任何补救措施，而线程池还会新建一个线程，保证线程池的正常工作（便于管理）。

### 引申问题

1、线程池采用了什么设计模式？采用了简单工厂模式，创建线程池使用工厂类提供的静态方法。

2、newFixedThreadPool(1)和newSingleThreadExector()有什么区别？newSingleThreadExector采用装饰器模式，对应的类是FinalizableDelegatedExecutorService，只对外暴露了ExecutorService接口，因此不能调用ThreadPoolExecutor中特有的方法；而newFixedThreadPool对外暴露的是ThreadPoolExecutor对象，强转之后可以调用setCorePoolSize方法进行修改。



## 19、读写锁使用起来有哪些要点？读写锁加锁流程？

使用的要点：

* 读锁不支持条件变量，写锁支持。
* 读写锁重入时不支持升级，持有读锁的情况下去获取写锁，会导致永久等待。
* 重入支持降级，即持有写锁的情况下获取读锁，会将写锁降级为读锁。

### 写锁

#### 加锁流程：

* acquire方法中使用tryAcquire方法尝试获得锁，成功就返回，失败就创建独占模式的队列节点，进入acquireQueued方法。
* acquireQueued方法中会进入一个死循环，检查当前node节点是否是队列中的第二个节点，如果是的话，会再次执行tryAcquire方法获取锁，失败的话会执行shouldParkAfterFailedAcquire方法，如果前一个节点的waitStatus是-1的话，则当前线程park，否则将前一个节点的waitStatus状态改为-1，并再次执行循环。
* tryAcquire中会获取state值，检查是否有读锁的存在，有读锁存在不能获取；检查是否有写锁存在，如果有写锁存在且持有线程不是本线程，也不能获取，如果是本线程，直接设置state加一，进行锁重入；如果上述情况不存在，则检查写锁是否应该阻塞，如果是公平锁的话，需要检查队列中有没有别的线程比自己先到，如果有则当前线程不能获取写锁，非公平锁则不需要阻塞，通过cas设置state状态上锁。

#### 释放流程：

* release方法中使用tryRelease方法尝试释放锁，如果释放成功，则唤醒阻塞队列中等待的线程，不需要更改头结点操作，此操作交给被唤醒的节点执行（阻塞的写锁使用setHead方法，阻塞的读锁使用setHeadAndPropagate方法）。

### 读锁

#### 加锁流程：

* acquireShared方法中使用tryAcquireShared方法尝试加读锁，返回值为负数表示失败，如果失败，则进入doAcquireShared方法执行。
* tryAcquireShared方法中会检查是否有写锁，如果有写锁且当前写锁持有线程不是自己，则返回-1；如果没有写锁，接着会cas尝试将读锁数量加一，如果cas失败，会进入fullTryAcquireShared方法中，此方法中会死循环，不断的尝试cas增加读锁数量，同时也会检测有没有写锁。
* doAcquireShared方法是阻塞读锁节点的方法，会将当前线程关联到一个node节点上，节点的模式为共享模式（写锁创建的节点模式是独占模式）。然后进入死循环，判断当前node节点是否为队列中第二个节点，如果是则再次执行tryAcquireShared方法，如果获取读锁成功，则执行setHeadAndPropagate更新头结点并唤醒队列中下一个状态为share的节点，如果获取锁失败则走shouldParkAfterFailedAcquire流程。
* setHeadAndPropagate方法中会将当前node节点设置为头结点，释放原来的头结点，然后判断队列中的下一个节点是否应该释放，如果下一个节点的状态是share，就属于应该释放的节点，进入doReleaseShared方法。
* doReleaseShared方法中判断头结点的waitStatus，如果为-1（下一个节点需要阻塞，使用一个枚举值Node.SIGNAL），则cas将其改为0，如果cas成功，则唤醒头结点的下一个节点；如果头结点的waitStatus为0，则cas将其改为-3（枚举值为Node.PROPAGATE,防止多线程执行情况下出现bug）。

#### 释放流程：

* 执行releaseShared方法，此方法中会使用tryReleaseShared方法释放读锁，如果释放成功（只有读锁数量为0才算释放成功），进入doReleaseShared方法执行，释放阻塞队列中的下一个节点（也有可能是写锁节点）。
* tryReleaseShared方法中会进入死循环，不断的使用cas修改state状态的值，使其值为原值减一。
* doReleaseShared和加锁流程中的一致，注意，其中并没有判断唤醒节点是否为读锁节点的步骤，判断的步骤需要在调用之前判断。



## 20、Java中的线程状态有哪些？

操作系统层面的有五种状态：初始状态（创建）、就绪状态、运行状态、阻塞状态、终止状态。

Java的api层面有六种状态：NEW、RANNABLE、BLOCKED、WAITING、TIME_WAITING、TERMINATED

![image-20230223152908712](D:\文档\学习笔记\学习疑问.assets\image-20230223152908712.png)

1、NEW是线程刚被创建，但是还没有调用start法的状态。

2、当线程被调用了start方法之后进入RUNNABLE，包含了操作系统层面的运行、阻塞、就绪状态，由于BIO导致线程的阻塞在Java中无法区分，仍然被认为是RUNNABLE状态。

3、当线程通过synchronized(obj)获取了对象锁之后，调用obj.wait()方法会导致线程状态从RUNNABLE转换为WAITING状态。

4、接着第3条，如果这时候有别的线程也获取了这个对象锁，并且调用了obj.notify()、obj.notifyAll()、t.interrupt()方法时，会导致wait的线程被唤醒来重新竞争对象锁，如果竞争锁成功则状态转换为WAITING  - >  RUNNABLE；如果竞争锁失败，则状态转换为WAITING  -> BLOCKED。

5、当前线程调用t.join()方法时，当前线程从RUNNABLE转换为WAITING状态。

6、接着第5条，t线程运行结束，或者调用了当前线程的interrupt()方法时，当前线程从WAITING转换为RUNNABLE状态。

### 总结

1、RUNNABLE --》 WAITING：调用wait()，join()，park()方法。反之这些等待状态解除了则从 WAITING --》RUNNABLE。

2、RUNNABLE --》TIMED_WAITING：调用wait(long n)，join(long n)，sleep(long n)，LockSupport.parkNanos(long nanos)等带有等待时间的方法会导致状态的转变。反之解除这些状态之后则从TIMED_WAITING --》RUNNABLE。

3、RUNNABLE --》BLOCKED：线程使用synchronized获取对象锁失败，则进入阻塞状态。当获取对象锁的线程释放对象锁时，会唤醒BOLCKED的线程，如果被唤醒的线程重新获取锁成功，则从BLOCKED --》RUNNABLE。

4、当前线程的所有代码执行完毕，进入TERMINATED状态。



## 21、以前版本中JUC的Semaphore会出现什么BUG？

​	当两个资源持有者并发的释放资源时，会导致唤醒的节点只有一个，这是因为原来版本的释放资源时只将头结点的waitStatus值cas改为0，通过是否为0判断当前是否应该唤醒下一个节点，当一个线程修改了头节点的状态，但是还没来得及将头结点释放时，另一个线程也想释放资源，但是一检查发现头结点的waitStatus为0，则不做任何操作就返回了，导致只释放了队列中的一个节点。

​	改进的版本在释放资源时使用了doReleaseShared方法，会判断头节点waitStatus，如果为-1，则cas修改为0；如果为0，则cas修改为-3（Node.PROPAGATE）。唤醒下一个节点的判断变为头节点的waitStatus值小于0，就进入尝试唤醒节点流程。



## 22、isInterrupted方法和interrupted方法的区别是什么？interrupt方法说一下？

**区别**：

1、isInterrupted是实例方法，必须要通过线程对象来调用；interrupted是静态方法，表示查看当前执行的线程的打断状态。

2、isInterrupted不会清除打断标记，而interrupted会清除。

**interrupt方法**：

1、实例方法，通过线程对象的引用来调用。

2、如果被打断的线程处于sleep、wait、join，会导致此线程抛出InterruptedException，并清除打断标记。

3、如果被打断的线程正在运行，则会设置打断标记。

4、park的线程被打断，也会设置打断标记。



## 23、Java怎么唤醒正在sleep的线程？

​	调用线程的interrupt方法使其抛出InterruptedException异常来打断线程。



## 24、什么是两阶段终止？

​	两阶段终止是一种用于结束线程的设计模式，比如有两个线程A和B，A线程想要终止B线程的执行，就可以采用两阶段终止模式。

​	利用打断机制来结束目标线程，线程B执行时通过判断自身的打断标记判断是否被其他线程打断了，如果被打断则退出执行，如果是sleep时，被打断会抛出InterruptedException异常，同时将打断标记清除，所以需要在catch中手动设置打断标记为true，这样也可以退出执行。

​	也可以使用volatile修饰的变量代替打断标记。



## 25、Java中怎么解决伪共享问题？

​	java中的@sun.misc.Contended注解可以解决伪共享问题。它的原理是在使用此注解的对象或字段的前后各增加128字节大小的填充，从而让CPU将对象读取到缓存中时占用不同的缓存行。



# JVM

## 1、为什么使用StringBuilder比字符串使用+拼接更加高效？

​	因为如果使用+进行拼接的话，编译成字节码的时候还是会创建StringBuilder进行字符串拼接，并且创建一个新的String对象作为返回，而且是每一次+的时候都会创建两个对象，而使用StringBuilder的话，只用创建一个StringBuilder对象和最终生成一个String对象返回。



## 2、新生代和老年代分别使用什么算法？为什么？

​	新生代：复制算法。因为复制算法的效率最高，但内存会有浪费，而新生代中进行垃圾收集是十分频繁的，所以选择效率最高的，内存使用有些浪费也是可以接受的。

​	老年代：标记压缩算法。老年代进行垃圾回收的次数比较少，并且经常存储一些大对象，标记压缩算法能够最大化利用内存空间，避免出现碎片现象。



## 3、什么是热替换？如何实现？热替换中每次不重新new一个类加载器会怎么样？

​	热替换是指在应用程序运行过程中，动态的将类修改并且重新加载到JVM，实现运行过程中更新功能。

​	如果使用同一个类加载器，那么加载这个类的时候会先判断是否加载过，加载过的话就不会重新加载了，所以就不能进行热替换。



## 4、动态链接与静态链接？



## 5、什么是内存屏障？如何做到内存屏障？

​	我的理解：内存屏障是解决重排序问题的一种机制，至于什么是重排序呢？重排序包括三种：编译器重排序、CPU重排序、内存系统的重排序。重排序会造成什么问题？并发场景下，会造成可见性问题，导致程序运行的结果不在想要的结果之中。



## 6、什么是三色标记法？并发垃圾回收器使用三色标记法会出现什么问题？如何解决这些问题？

三色标记法是一种并发可达性分析算法。

通过三种颜色来标识对象的状态：

* 白色表示对象尚未被垃圾回收器访问过。
* 灰色表示对象已经被垃圾回收器访问过，但这个对线上至少存在一个引用还没有被扫描过。
* 黑色表示对象已经被垃圾回收器访问过，并且这个对象的所有引用已经扫描过。

**执行过程**

​	从GC Roots开始，垃圾回收器对访问过的对象进行标记，访问到一个对象，先将其从白变成灰，然后访问这个对象所包含的其他对象，把那些（当前灰色对象引用的对象）全部标记为灰色之后，将当前对线标记为黑色。

**问题**

​	会产生**对象消失**问题——原本应该是黑色的对象被当做白色对象处理，被垃圾回收器回收掉了。

**解决方案**

​	出现对象消失问题有两个条件，只有这两个条件同时满足时，才会发生对象消失问题：

* 插入了一条或多条从黑色对象到白色对象的新引用。
* 删除了全部从灰色对象到该白色对象的直接或间接引用。

​	因此，只要破坏这两个条件中的其中一个，就可以解决对象消失问题。有两种解决方案：**增量更新**、**原始快照**。

1、增量更新破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，将这个引用记录下来，等到并发扫描结束之后，再将这些记录过的引用关系中黑色对象为根，重新扫描一遍。可以理解为：黑色对象一旦新插入了指向白色对象的引用，就退化为灰色对象。

2、原始快照破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，记录下来，并发扫描结束之后，再将记录下来的引用关系中的灰色对象为根，重新扫描一遍。可以理解为：无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象关系来进行搜索。

**应用**

1、CMS使用的是增量更新来做并发标记。

2、G1、Shenandoah使用原始快照。



## 7、Tomcat是如何解决类的隔离问题的？

​	Tomcat通过自定义的类加载器WebAppClassLoader打破了双亲委托机制，目的就是为了优化加载Web应用目录下的类。在Tomcat中，由于不同的web应用可能加载类名相同的类，但是这些类应该当做不同的类来处理，为了应对这种情况，Tomcat自定义一个类加载器WebAppClassLoader，并且给每一个web应用创建一个类加载器实例用以加载自身所使用的类。

​	Tomcat类加载器整体结构：

![image-20230307173852955](D:\文档\学习笔记\学习疑问.assets\image-20230307173852955.png)

​	CommonClassLoader：Tomcat中最基本的类加载器，加载路径中的类可以被Tomcat容器以及webapp所访问。

​	CatalinaClassLoader：Tomcat容器私有的类加载器，加载路径中的类对于webapp不可见。

​	SharedClassLoader：各个webapp共享的类加载器，加载的类对于每个webapp可见，对于Tomcat容器不可见。

​	WebappClassLoader：每个webapp私有的类加载器，加载的类只对于当前webapp是可见的，对于其他webapp和Tomcat容器不可见。



## 8、为什么需要自定义类加载器？如何自定义类加载器？

**为什么**

1、隔离加载类。

2、修改类加载的方式。

3、扩展加载源。例如从数据库、路由器等不同地方加载类。

4、防止源码泄漏。可以对字节码文件进行加密，使用的时候通过自定义的类加载器来对其进行解密。

**自定义步骤**

1、继承抽象类ClassLoader。

2、重写方法。jdk1.2之前，重写loadClass()方法；jdk1.2之后不建议直接重写loadClass()方法，而是重写findClass()方法。

3、如果没有太复杂的需求，可以直接继承URIClassLoader类，避免自己编写findClass()方法。



## 9、获取类加载器有几种方法？

1、通过类对象来获取类加载器：clazz.getClassLoader()。

2、通过当前线程获取：Thread.currentThread().getContextClassLoader()。

3、获取系统类加载器：ClassLoader.getSystemClassLoader()。

4、获取调用的类加载器：DriverManager.getCallerClassLoader()。



## 10、双亲委派机制原理？有什么优势？

**原理**

1、如果一个类加载器收到了类加载请求，它并不会自己先去加载，而是把这个请求委托给父类的加载器去执行。

2、如果父类加载器还存在其父类加载器，则进一步向上委托，依次递归，请求最终将到达顶层的启动类加载器。

3、如果父类加载器可以完成类加载任务，就成功返回，倘若父类加载器无法完成此加载任务，子加载器才会尝试自己去加载，这就是双亲委派模式。

4、父类加载器一层一层往下分配任务，如果子类加载器能加载，则加载此类，如果将加载任务分配至系统类加载器也无法加载此类，则抛出异常。

**优势**

1、避免类的重复加载。

2、保护程序安全，防止核心API被随意篡改。



## 11、了解ZGC收集器吗，讲讲染色指针，读屏障？

### ZGC

​	是一款基于Region内存布局的，不设分代的，使用了读屏障、染色指针和内存多重映射等技术来实现可并发的标记-整理算法的，以低延迟为首要目标的一款垃圾收集器。

### 内存布局

​	ZGC也采用基于Region的堆内存布局，但与G1不同的是ZGC的Region具有动态性：动态创建和销毁，以及动态的区域容量大小。在x64硬件平台下，ZGC的Region可以具有大、中、小三类容量：

* 小型region：容量固定为2mb，用于放置小于256kb的小对象。
* 中型region：容量固定为32mb，用于放置大于等于256kb但小于4mb的对象。
* 大型region：容量不固定，可以动态变化，但必须为2mb的整数倍，用于放置4mb及以上的大对象，每个大region中只会存放一个大对象。大型region在ZGC实现中是不会被重分配的，因为复制一个大对象的代价非常高。

### 染色指针

**是什么？**染色指针是一种直接将少量额外的信息存储在指针（内存地址）上的技术。

**原理**

1、现代操作系统内存地址是64位的，但实际上用不到那么多位（基于需求、性能、成本考虑）。64位Linux操作系统只支持47位（128TB）的进程虚拟地址空间和46位（64TB）的物理地址空间；64位Windows操作系统只支持44位的物理地址空间。

2、基于以上前提，ZGC的使用内存地址46位中的高4位作为标识，标记其引用对象的三色状态标记、是否进入重分配集、是否只能通过finalize()方法才能访问到。

**优点**

1、一旦某个Region的存活对象被移走之后，这个Region立即就能被释放和重用掉，而不必等待整个堆中所有指向该Region的引用都被修正之后才能清理。为什么？因为ZGC拥有自愈功能，会为重分配集中的每个region维护一个转发表，记录从旧对象到新对象的转向关系，由于染色指针的存在，ZGC仅从对象的引用上就能知道对象是否在重分配集中，如果用户线程并发访问了重分配集中的对象，那么这次访问会被预置的内存屏障所截获，然后立即根据region上的转发表将访问转发到新的对象上，并且更新该引用的值，使其直接指向新对象。

2、染色指针可以大幅减少在垃圾收集过程中内存屏障的使用数量。由于ZGC不设置分代，天然就没有跨代引用，无需写屏障维护卡表，并且可以直接将对象引用变动信息维护在染色指针中，省去专门的记录操作。

3、染色指针可以作为一种可扩展的存储结构用来记录更多与对象标记、重定位过程相关的数据，以便日后进一步提高性能。

4、由于JVM只是作为一个运行在操作系统之上的普通进程，随意的定义内存地址中的高位为标识，操作系统是无法支持的，所以ZGC使用了虚拟内存映射技术——**多重映射**来使用染色指针，它的原理是将高4位看做是地址的分段符，将不同地址段都映射到同一个物理内存空间，就可以使用染色指针了。

**缺点**

1、由于可用的内存地址中的高4位用来作为标识了，所以ZGC能够管理的内存不能超过4TB。

2、不支持32位平台。

3、不支持压缩指针。



**垃圾回收过程**

1、并发标记：遍历对象图做可达性分析，ZGC的标记是在指针上而不是在对象上进行的。

2、并发预备重分配：根据特定查询条件统计出本次收集过程要清理哪些Region，将这些Region组成重分配集，与G1中的回收集不同的是，重分配集只是决定了里面的存活对象会被重新复制到其他的Region中，里面的Region会被释放（也有Region没被释放的情况？），并不能说回收行为就只是针对这个集合里面的Region进行。jdk12的ZGC中开始支持的类卸载以及弱引用的处理也是在这个阶段完成的。

3、并发重分配：重分配是ZGC执行过程中的核心阶段，此阶段需要把重分配集中的存活对象复制到新的Region上，并为重分配集中的每个Region维护一个转发表。

4、并发重映射：重映射所做的就是修正整个堆中指向重分配集中旧对象的所有引用，因为旧引用是可以自愈的，所以并发重映射并不是一个必须要“迫切”去完成的任务，清理这些旧引用主要是为了不变慢（清理完可以释放转发表），因此ZGC巧妙的地把并发重映射阶段要做的工作合并到了下一次垃圾收集循环中的并发标记阶段里完成，反正它们都是要遍历所有对象的，这样就节省了一次遍历对象图的开销。



## 12、什么是动态分派？虚方法表是什么？

​	动态分派是jvm中执行实例方法的一种机制，它的流程是：对象执行方法时进入对象类的方法区中寻找是否有这个方法的代码，如果有的话，需要检查是否有权限执行，如果没有权限则抛出IllegalAccessError异常；如果当前类没有这个方法，则按照继承关系往父类寻找；如果始终没有找到对应的方法，抛出AbstractMethodError异常。

​	在面向对象编程中，会很频繁的使用到动态分派，如果每次都需要走一个完整的流程，效率太低，为此jvm中每个类维护了一个虚方法表，其中存储所有可能被重写的方法（虚方法）对应的地址，当需要执行某个方法时，直接从虚方法表中查询，就不需要频繁的进行动态分派了。

​	虚方法表会在类加载的链接阶段被创建并初始化，类的变量初始化值准备完成之后，jvm会把该类的虚方法表也初始化完成。



## 13、类的加载阶段分为哪几个过程？详细说说？

### 加载

​	通过类加载器将磁盘上所需要的class文件加载到方法区，生成一个java.lang.Class对象，作为方法区这个类的各种数据的访问入口。

### 链接

#### 验证

​	确保Class文件的字节流中包含信息符合当前虚拟机要求，保证被加载类的正确性，不会危害虚拟机自身安全。主要包括四种验证：文件格式验证、元数据验证、字节码验证、符号引用验证。

​	例如：合法的class文件的开头都是cafebabe。

#### 准备

​	为类变量（静态变量）分配内存地址并初始化，不包括final修饰的变量和实例变量。final修饰的变量是在编译阶段就确定了值，准备阶段会显示初始化。实例变量是创建对象时分配内存地址并初始化的（在堆内存中）。

#### 解析

​	将符号引用转换为直接引用。在class文件中，对于方法等（字段）的调用是以符号引用的形式进行的，即使用一个符号代表要调用的方法地址，在解析阶段需要确定实际调用的方法的内存地址，并将符号引用替换为实际引用。

​	实际上，解析操作往往会在jvm执行完初始化步骤之后再执行。

### 初始化

​	初始化阶段就是执行clinit方法。生成class文件时，编译器会将程序中所有为静态变量赋值的语句和静态代码块中的语句生成一个clinit方法。clinit方法的执行是线程安全的，jvm保证只能由一个线程来完成加载类的操作。



## 14、java中类的初始化时机有哪些？

1、创建类的对象。

2、调用类的静态方法和属性。

3、初始化类的子类，初始化一个类时，会先初始化该类的父类。

4、反射。

5、启动类会被初始化。

6、java.lang.invoke.MethodHandle实例的解析结果REF_getStatic、REF putStatic、REF_invokeStatic句柄对应的类没有初始化，则初始化。



## 15、出现了OOM问题的解决思路？

1、通过分析工具确定问题。首先通过内存映像分析工具（如Eclipse Memory Analyzer）对dump出来的堆转储快照进行分析，重点是确定内存中的对象是否是必要的，也就是要分清楚到底是出现了**内存泄漏**还是**内存溢出**。

2、如果是发生了内存泄漏，可进一步通过工具查看泄漏对象到GC Roots的引用链。于是就能找到泄漏对象是怎样的路径和GC Roots相关联导致垃圾回收器无法自动回收它们的。掌握了泄漏对象的类型信息，以及GC Roots引用链的信息，就可以比较准确地定位出泄漏代码的位置。

3、如果不存在内存泄漏，就应该检查虚拟机的参数（-Xmx与-Xms），与机器物理内存对比查看是否还可以调大，或是从代码上检查是否存在某些对象生命周期过长、持有状态时间过长的情况，尝试减少程序运行期的内存消耗。



## 16、对象什么时候会进入老年代？

1、当分代年龄达到阈值的时候，默认阈值为15。

2、超大对象，无法在新生代分配内存，直接进入老年代。

3、如果survivor区中相同年龄的所有对象大小的总和大于survivor区的一半，年龄大于或等于该年龄的对象可以直接进入老年代。

4、survivor区满了时，对象可以直接进入老年代（具体规则待补充）。



## 17、说一说字符串常量池？为什么要将字符串常量池调整到堆内存中？

**字符串常量池**

1、字符串常量池是存在于堆内存中的固定大小的hashtable，默认长度是1009。

2、使用-XX:StringTableSize可以设置字符串常量池的长度。

3、jdk6中字符串常量池是固定的，长度为1009，对长度的设置没有限制；jdk7中默认长度为60013，对长度的设置没有限制；jdk8中默认长度也是60013，但是对长度设置有限制：设置的最小值为1009。

4、通过双引号声明的字符串会直接存储在常量池中，如果不是双引号声明的String对象，可以调用intern()方法，将其的值保存到字符串常量池中。

**调整原因**

1、永久代的默认空间大小比较小。

2、永久代垃圾回收频率低，而字符串是程序开发中非常常用的，会有大量空间浪费（很多字符串只使用很短的一段时间）。字符串太多会导致Full GC产生STW影响程序性能，甚至是产生OOM。



## 18、String.intern()方法有什么用？各版本中有什么区别？

1、intern是一个native方法，调用的是低层C的方法。

2、调用String.intern()方法，会去字符串常量池中判断是否有该字符串存在，如果存在则返回此字符串在常量池中的地址；如果不存在，则在常量池中创建一份，并返回地址。

区别：在jdk6及之前如果是new出来的String对象使用intern方法，而常量池中没有这个字符的话，会新创建一个字符串对象；而jdk7及以后则改为了将这个String对象的引用放在字符串常量池中。



## 19、调用对象的toString()方法会导致字符串被加载到字符串常量池中吗？

​	具体需要看toString()方法的实现，是返回了一个字符串字面量还是new出来的String，如果是字面量就会加载到字符串常量池，如果是new出来的，就不会加载到字符串常量池。



## 20、字符串拼接操作的原理是什么？

1、常量和常量的拼接结果会存在字符串常量池中，原理是编译期优化。

2、拼接前后，只要有一个是变量（非final变量），结果就在堆中。原理是使用了StringBuilder，jvm会优化成使用StringBuilder来append拼接的前后两部分，然后再调用StringBuilder的toString()方法。

3、如果拼接前后是final修饰的变量，仍然会使用编译期优化，和常量拼接一样。



## 21、垃圾回收算法分为哪几个阶段？分别有什么算法，详细说说？

分为两个阶段：标记阶段、清除阶段。

### 标记阶段

#### 引用计数算法

**思路**

​	对于每个对象维护一个整型的引用计数器属性，用于记录对象被引用的情况。只要有对象（或变量）引用了当前对象，引用计数就加1；当某个引用失效时，引用就减1。如果一个对象的引用计数为0，则说明没有其他地方引用当前对象，可进行回收。

**优点**

1、实现简单，垃圾对象易于辨识。

2、执行效率高，回收没有延迟性。

**缺点**

1、每个对象都需要单独的引用计数器，增加了空间的开销。

2、每次进行对象的引用都需要更新对象的引用计数器，有一定的时间开销。

3、有一个致命的问题：无法处理循环引用问题（两个对象相互引用，即使没有别的地方引用这两个对象了，也无法回收这两个对象），将会导致内存泄漏。

**实际使用**

​	Python中是使用支持引用计数算法的，它是如何解决循环引用问题的？1、手动解除，就是在合适的时机解除引用关系；2、使用弱引用，弱引用在发生垃圾回收时会直接被回收掉。



#### 可达性分析算法

**思路**

​	可达性分析算法是以根对象（GC Roots）为起点，按照从上至下的方式搜索根对象集合锁连接的目标对象是否可达。搜索所走过的路径称为引用链。如果目标对象没有在任何引用链中，则是不可达到的，意味着该对象已经死亡，可以标记为垃圾对象。

**优点**

1、不会出现循环引用问题。

**实际使用**

​	Java、C#中使用的就是可达性分析算法。



### 清除阶段

#### 标记清除

**过程**

​	从根节点开始遍历，标记可达对象（对象头中进行标记）。标记完成后，对堆内存从头到尾进行线性遍历，回收不可达对象。

**缺点**

​	1、清理完成后的内存空间是不连续的，会产生内存碎片。使用空闲列表法维护内存使用情况。

​	2、效率不算高，进行GC的时候，需要停止整个应用程序，用户体验差。

**注意**

​	清除并不是真的将内存置空，而是在空闲列表中标记这块内存已经为空了，可以分配这块内存，下次分配对象时会重新覆盖掉这块内存。所以这也是创建对象时需要初始化以及局部变量使用时必须要手动初始化的原因。



#### 复制算法

**过程**

​	将可用的内存分为两部分，每次只使用其中一部分，在垃圾回收时将正在使用的内存中的存活对象复制到未被使用的内存块中，之后清除正在使用的内存块中的所有对象，交换两个内存块的角色，完成垃圾收集。

**优点**

​	1、实现简单，运行高效，遍历根节点过程中就可以完成垃圾收集。

​	2、复制后保证内存空间的连续性，不会出现内存碎片。

**缺点**

​	1、需要两倍的内存空间，内存使用率低。

​	2、复制对象需要改变对象的内存地址，引用对象的地方也需要进行相应的改动，对于G1这种拆分成大量region的GC，意味着GC需要维护region之间对象引用关系，不管是内存占用还是时间开销都不小。

**应用场景**

​	1、系统中的垃圾对象很多时适合使用，垃圾对象较多，而存活对象较少的话，复制的开销不会很大，效率较高。

​	2、新生代中产生垃圾对象较多，适合使用，回收性价比高，所以新生代中使用的是复制算法：survivor区。



#### 标记压缩

**过程**

​	分为两个阶段，第一阶段对存活对象进行标记，第二阶段将所有存活对象移动到内存的一端，按顺序排放。之后，清理边界外所有的空间。

**优点**

​	1、垃圾收集后会对内存进行整理，消除内存碎片（外部碎片）。

​	2、维护空闲内存时使用一个指针表示未使用的内存地址的开始处即可，减少维护成本。

​	3、相比于复制算法，内存充分利用了起来。

**缺点**

​	1、垃圾收集时需要移动对象，整理内存，是三种算法中效率最低的。

​	2、移动对象时，如果对象被其他对象引用，还需要调整引用地址，需要增加维护成本（和复制算法一样）。

​	3、移动过程中需要全程暂停用户应用程序。



#### 总结

|              | 标记清除           | 标记整理         | 复制                                  |
| ------------ | ------------------ | ---------------- | ------------------------------------- |
| **速率**     | 中等               | 最慢             | 最快                                  |
| **空间开销** | 少（但会堆积碎片） | 少（不堆积碎片） | 通常需要活对象的2倍空间（不堆积碎片） |
| **移动对象** | 否                 | 是               | 是                                    |



### 其他回收算法

#### 分代收集算法

​	分代收集算法，是基于这样一个事实：**不同的对象的生命周期是不一样的。因此，不同生命周期的对象可以采取不同的收集方式，以便提高回收效率。**一般是把Java堆分为新生代和老年代，这样就可以根据各个年代的特点使用不同的回收算法，以提高垃圾回收的效率。



#### 增量收集算法

**为什么需要**

​	上述现有的算法，在垃圾回收过程中，应用软件将处于一种Stop the World的状态。在**Stop the World**状态下，应用程序所有的线程都会挂起，暂停一切正常的工作，等待垃圾回收的完成。如果垃圾回收时间过长，应用程序会被挂起很久，将严重影响用户体验或者系统的稳定性。为了解决这个问题，即对实时垃圾收集算法的研究直接导致了增量收集（Incremental Collecting）算法的诞生。

**增量收集算法基本思想**

1.  如果一次性将所有的垃圾进行处理，需要造成系统长时间的停顿，那么就可以让垃圾收集线程和应用程序线程交替执行。**每次，垃圾收集线程只收集一小片区域的内存空间，接着切换到应用程序线程。依次反复，直到垃圾收集完成。**
2.  总的来说，增量收集算法的基础仍是传统的标记-清除和复制算法。增量收集算法通过**对线程间冲突的妥善处理，允许垃圾收集线程以分阶段的方式完成标记、清理或复制工作**

**增量收集算法的缺点**

​	使用这种方式，由于在垃圾回收过程中，间断性地还执行了应用程序代码，所以能减少系统的停顿时间。但是，因为线程切换和上下文转换的消耗，会使得垃圾回收的总体成本上升，**造成系统吞吐量的下降**。



#### 分区算法

​	一般来说，在相同条件下，堆空间越大，一次GC时所需要的时间就越长，有关GC产生的停顿也越长。为了更好地控制GC产生的停顿时间，将一块大的内存区域分割成多个小块，根据目标的停顿时间，每次合理地回收若干个小区间，而不是整个堆空间，从而减少一次GC所产生的停顿。



## 22、GC Roots有哪些？

1、虚拟机栈局部变量表中引用的对象。

2、本地方法栈内JNI（本地方法）中引用的对象。

3、静态变量（在堆中）引用的对象。

4、方法区（或堆中）中常量引用的对象。例如字符串常量池引用的对象。

5、所有被同步锁synchronized持有的对象。

6、JVM自身运行所引用的对象。例如系统类加载器、常驻的异常对象（NullPointerException）、基本数据类型对应的Class对象等。

7、反映JVM内部情况的JMXBean。

**总结**

1、除了堆空间外，其他的内存区域都可以作为GC Roots，例如：虚拟机栈、本地方法栈、方法区等。

2、除了这些固定的GC Roots集合外，根据用户所选的垃圾收集器以及当前回收的内存区域不同，还可以有其他对象“临时性”地加入，共同构成完整的GC Roots集合。比如：分代收集时针对新生代的垃圾回收，需要考虑将老年代中的对象加入GC Roots中（但并不是将整个老年代当做GC Roots，而是使用记忆集记录跨代引用）。



## 23、什么是记忆集？什么是卡表？卡表会出现什么问题？

**记忆集**

​	由于跨代引用的存在，以回收新生代为例，如果有老年代的对象引用了新生代的对象，这就属于一个跨代引用，垃圾回收时需要将老年代也视为GC Roots，但是如果要遍历整个老年代，效果太差，故而引出了记忆集这个概念，记忆集就是用于记录跨代引用的数据结构，在垃圾回收时，会将记忆集中的引用也视为GC Roots。

**记忆集的精度**

​	如果不考虑效率和成本的话，最简单的实现可以用非收集区域中所有含跨代引用的数组来实现这个数据结构，这种方案无论是空间占用还是维护成本都相当高昂。而在垃圾收集的场景中，收集器只需要通过记忆集判断某一块非收集区域是否存在有指向了收集区域的指针就可以了，不需要了解跨代指针的全部细节。列举可选择的精度：

1、字长精度：每个记录精确到一个机器字长，该字包含跨代指针。

2、对象精度：每个记录精确到一个对象，该对象里有字段含有跨代指针。

3、卡精度：每个记录精确到一块内存区域，该区域内有对象含有跨代指针。

**卡表**

​	记忆集精度中的卡精度所指的是一种称为”卡表“的方式去实现记忆集。也就是说，记忆集是一种抽象的概念，它可以有不同的实现，而卡表就是其中一种实现。

**卡表的实现**

​	卡表最简单的形式可以只是一个字节数组，而HotSpot中也是这样做的，使用字节数组CARD_TABLE实现卡表，数组中的每一个元素都对应着内存区域中一块特定大小的内存块——卡页。HotSpot中卡页的大小是2的9次幂（512字节）。如果某个卡页中有跨代引用，那么将卡表中对应下标的元素表示为1即可。

**卡表的维护**

卡表该如何维护呢？什么情况下需要将卡表变脏？该怎么变脏？

1、当卡表元素标识的内存地址中出现了跨代引用时，需要将卡表标记上，需要在发生引用关系赋值的那一刻将卡表变脏。

2、HotSpot中使用**写屏障**技术维护卡表状态。写屏障可以看做是在虚拟机层面对“引用字段类型赋值”这个操作的AOP切面，在引用对象赋值时会产生一个环形通知，供程序执行额外的动作，比如将卡表对应的元素标记为脏。

3、应用写屏障后，虚拟机就会为所有赋值操作生成相应的指令，如果在写屏障中增加了更新卡表的操作，无论更新的是不是老年代对新生代的引用，都会产生额外的开销，不过这个开销相比于MinorGC时扫描整个老年代的代价相比还是低很多的。

**卡表的问题**

1、卡表的更新在高并发场景下会出现“伪共享”问题。伪共享问题简单来说就是虽然使用了缓存，但是却和没使用缓存的效果一样。主要原因是现代缓存是以缓存行为单位进行缓存的读取和写回的，如果两个线程同时要修改同一个缓存行中的内容就会出现问题，这时候就会出现缓存失效，修改失败，甚至是采用同步来进行修改，影响性能。

2、现代处理的缓存一般都会有多个字节（比如L1缓存64字节），而卡表一个元素只占一个字节，64个卡表对应的卡页总内存为32kb（64×512），也就是说如果有两个线程更新的对象刚好在这32kb内，就会出现伪共享问题。

3、伪共享问题的一种解决方案是不采用无条件的写屏障，而是先检查卡表标记，只有当要更新的卡表标记未被标记过时才将其标记为脏。jdk7之后，HotSpot虚拟机增加了一个新参数：-XX:+UseCondCardMark，用来决定是否开启卡表更新的检查。



## 24、了解根节点枚举吗？详细说说？

​	迄今为止，所有收集器在根节点枚举这一步骤时都是必须要暂停用户线程的，因此如果这一步骤耗时非常久的话，会严重影响程序性能，比如每次垃圾收集时都需要遍历每个线程栈帧，从局部变量表中获取引用信息，或者是遍历方法区，找到常量引用的对象和静态变量（静态变量的引用在jdk7之后存在了堆中）。

​	在HotSpot的解决方案里，使用一组称为OopMap的数据结构存放着对象引用信息，也就是存放作为GC Roots的引用信息。

1、一旦类加载动作完成时，HotSpot会把对象内什么偏移量上是什么类型的数据计算出来，这时就会将引用信息存放到OopMap中。

2、除此之外，在即时编译过程中，HotSpot也会在**特定的位置**记录下栈里和寄存器里哪些位置是引用。

​	这样收集器在扫描时就可以直接从OopMap中得到GC Roots，而不必从方法区等GC Roots中一字不漏的查找对象引用关系。



## 25、什么是安全点？安全区域呢？

​	安全点是jvm规定的可以进行垃圾回收的特定位置，前面所说的OopMap记录时的特定位置其实就是安全点，例如以方法调用、循环跳转、异常跳转等指令作为安全点。

**为什么需要安全点**

​	可能导致OopMap内容变化的指令非常多，如果为每一条指令都维护OopMap，那将会需要大量的额外空间，这样垃圾收集伴随的空间成本就会变得无法忍受的高昂。因此引入了安全点这个概念，用户程序只有到达安全点后才能够暂停下来开始垃圾收集。

**安全点的选取**

​	安全点的选定不能太少以至于让收集器等待时间过长，也不能太过频繁以至于过分增大运行时的内存负荷。安全点的选取是以*是否具有让程序长时间执行的特征*为标准进行选定的。例如方法调用、循环跳转、异常跳转。

**中断时机**

​	这时还有别的问题，如何在垃圾收集发生时让所有线程都跑到最近的安全点，然后停顿下来呢。有两种方案：

1、抢先式中断：发生垃圾收集时，系统首先把所有用户线程中断，如果有用户线程不在安全点上，就恢复这个线程的执行，让它一会再重新中断，直到跑到安全点上。缺点：效率不高，因为中断线程之后可能还需要它重新跑起来，浪费了时间。

2、主动式中断：当需要垃圾收集时，不直接对线程操作，仅仅简单的设置一个标志位，各个线程执行时会不停地主动去轮询这个标志，一旦发现中断标志为真时就自己在最近的安全点上主动中断挂起。轮询标志的位置和安全点是重合的，除了安全点之外，在创建对象和其他需要在对上分配内存的地方也会轮询标志，这是为了检查是否即将要发生垃圾收集，避免没有足够内存分配新对象。

​	在主动式中断中，由于需要频繁的去轮询，所以轮询操作一定要足够高效，HotSpot中使用内存保护陷阱的方式实现了这个轮询操作，只需要一条test指令即可完成轮询：test %eax,0x16100 标记时只需要将0x16100处的地址设置为不可读，执行这条语句的时候就会产生一个自陷异常信号，然后再预先注册的异常处理器中挂起线程实现等待。

**作用**

1、只在安全点进行OopMap的更新。

2、只在安全点进行垃圾回收。

**安全区域**

​	只有安全点还是不够完善，因为当线程进入阻塞状态或sleep状态，比如阻塞IO时，线程无法响应虚拟机的中断请求，也不能走到安全点去中断挂起自己，虚拟机也不可能等待线程恢复并走到安全点再进行垃圾收集操作。于是引出了安全区域，安全区域是指能够确保在某一段代码片段之中，引用关系不会发生变化的区域。

​	当用户线程执行到安全区域里面的代码时，首先会标识自己已经进入了安全区域，那样当这段时间里虚拟机要发起垃圾收集时就不必去管这些线程了。当线程离开安全区域时，它要检查虚拟机是否已经完成了根节点枚举，如果没完成则必须一直等待，直到收到可以离开安全区域的信号为止。



## 26、了解对象的finalization机制吗，详细说说？

### finalize()方法

​	当垃圾回收器准备回收一个对象时，会先调用这个对象的finalize()方法。一般会在finalize方法中进行资源的释放和清理工作，比如关闭文件、套接字和数据库连接等。

### 对象的三种状态

由于finalize()方法的存在，对象会处于三种可能的状态之一：

1、可触及的：可以到达的对象，不会被回收。

2、可复活的：对象的所有引用都被释放，但是对象的finalize还没有被执行，对象可能在finalize方法中被复活。

3、不可触及的：对象的finalize方法被调用，并且没有复活，等待被回收。

### 回收过程

判断一个对象是否可回收，至少要经历两次标记过程，当对象不可达时，进行第一次标记。

![image-20230302172134898](D:\文档\学习笔记\学习疑问.assets\image-20230302172134898.png)

GC会对F-Queue队列中的对象进行第二次标记。如果在finalize方法中，对象和引用链上的任何一个对象建立了联系，那么第二次标记时，该对象会被移出“即将回收”的集合。



## 27、内存溢出和内存泄漏是什么？

**内存溢出**

​	当虚拟机的内存消耗殆尽，不足以支持继续运行时，就会抛出OutOfMemory异常，这种情况就是内存溢出了。

**内存泄漏**

​	应该被回收掉的对象却无法回收，也就是内存被不再使用了的对象占用了，会影响程序的后续执行，这种情况叫做内存泄漏。内存泄漏可能会造成内存溢出。

​	例子：静态变量引用的对象如果不使用的话，应该要设置为null，否则会造成内存泄漏；一些提供close()的资源未关闭也会导致内存泄漏，例如数据库连接、io连接。



## 28、强软弱虚四种引用各有什么特点？

**强引用**

1、可以直接访问对象。

2、指向的对象不会被回收，虚拟机宁愿抛出OOM也不会回收强引用所指的对象。

3、会导致内存泄漏。

**软引用**

1、内存足够时，不会进行回收，内存不够时会进行回收，当进行垃圾回收时，会先回收不可达对象，如果回收完内存还是不够用，则将软引用进行回收。

2、可以用来实现内存敏感的缓存。

3、可以获取到对象。

**弱引用**

1、只有弱引用指向的对象，一旦发生垃圾回收时，就会被回收掉。

2、可以获取到对象。

**虚引用**

1、主要用来做对象回收跟踪。

2、一个对象是否有虚引用，完全不会影响对象的声明周期，如果一个对象只有虚引用，那么它和没有引用几乎是一样的。

3、不能单独使用，必须和引用队列一起使用，无法获取被引用的对象。



## 29、了解垃圾回收器吗？详细说说CMS和G1？

### Serial回收器

**特点**

1、单线程，串行回收，使用“stop the world”机制进行垃圾回收。

2、提供配套的垃圾回收器，Serial回收器负责回收新生代，采用复制算法，Serial Old回收器负责回收老年代，采用标记压缩算法。

3、是Client模式下默认的垃圾回收器（新生代和老年代）。

4、Serial Old在Server模式下有两个用途：与新生代的Parallel Scavenge配合使用；作为老年代CMS收集器的后备垃圾收集方案。

**优点**

实现简单，在单线程的机器上比并行的垃圾收集器效率高，因为不需要进行频繁的上下文切换。



### ParNew回收器

**特点**

1、是Serial回收器的多线程版本，只负责新生代的垃圾回收，除了垃圾收集时采用并行回收的方式执行外，和Serial回收器几乎没有任何区别。

2、复制算法、“stop the world”机制。

3、除了Serial之外，目前只有ParNew能和CMS配合工作。



### Parallel回收器

**特点**

1、拥有负责新生代的Parallel Scavenge和负责老年代的Parallel Old的配套垃圾回收器。

2、新生代：复制算法、并行回收、“stop the world”机制；老年代：标记压缩算法、并行回收、“stop the world”机制。

3、Parallel Scavenge和ParNew不同在于：**吞吐量优先**，它的目标是达到一个可控制的吞吐量；自适应调节策略，动态调整内存分配，以达到一个最优的吞吐量或低延迟。

4、Parallel Scavenge适合在后台计算而不需要太多交互的任务，例如：执行批量处理、科学计算的应用程序。

5、是jdk8中的默认垃圾回收器。

**参数**

1、-XX:+UseParallelGC，手动指定年轻代使用Parallel Scavenge GC，同时也会激活老年代使用Parallel Old GC。

2、-XX:+UseParallelOldGC，手动指定老年代使用Parallel Old GC，同时也会激活年轻代使用Parallel Scavenge GC。

3、-XX:ParallelGCThreads，设置年轻代垃圾收集线程数量，最好设置和CPU核心数量相同。默认情况下，CPU核心数量小于8个，此参数值等于CPU核心数；大于8个，此参数取值为：3 + [5 * CPU_Count]/8。

4、-XX:MaxGCPauseMillis，设置垃圾收集时的最大停顿时间，单位是毫秒。为了尽可能地把停顿时间控制在此参数设置的数值内，收集器工作的时候会调整java堆大小或者其他一些参数。该参数需谨慎使用。

5、-XX:+UseAdaptiveSizePolicy，设置Parallel Scavenge收集器具有自适应调节策略，开启后，年轻代大小、Eden和Survivor比例、晋升老年代的年龄大小等参数会被自动调整，已达到堆大小、吞吐量和停顿时间之间的平衡点。手动调优困难时，可以直接使用这种模式。



### CMS回收器

**特点**

1、jdk1.5时期，HotSpot推出了CMS，这是一款在强交互应用中具有划时代意义的垃圾收集器。

2、是HotSpot虚拟机中第一款真正意义上的并发收集器，第一次实现了垃圾收集与用户线程同时工作。

3、关注点是**低延迟**，尽可能的缩短垃圾收集时用户线程的停顿时间。

4、采用标记清除算法，也会出现“stop the world”。

5、作为老年代的垃圾收集器，却无法和Parallel Scavenge配合工作（实现的框架不同，无法兼容），所以jdk1.5使用CMS收集老年代时，新生代只能从ParNew或Serial中选择一个。

**工作过程**

1、初始标记

2、并发标记

3、重新标记

4、并发清理：由于CMS采用标记清除算法，不需要移动存活对象，所以这部分操作也是可以和用户线程并发执行的。



### G1回收器

**特点**

1、采用分区算法，保留分代收集思想，不过将新生代和老年代都分成了一个个的region，是可以不连续的，所有的region大小相同，而且在jvm生命周期内不会改变。

2、将region作为单次垃圾回收的最小单位，根据每个region回收的价值（回收所获得的空间大小以及回收所需时间的经验值）大小维护一个列表，优先回收价值高的region，保证了G1在有限的时间内获取尽可能高的收集效率。

3、除了新生代和老年代的region之外，还新加了一个Humongous Region用于存放大对象，因为如果对象太大的话，会直接进入老年代中，但这些大对象可能是存活时间比较短的，所以单独使用一个区域用来存放，当对象的大小超过一个region大小的一半时，会使用Humongous Region存放。

4、由于分成了很多的region，所以跨代引用的维护就变得更加麻烦了，需要给每个region都维护一个记忆集，并且记忆集的结构是一个hashtable，key是引用当前region的其他region的开始地址，value是一个卡表索引的集合（含有的跨代引用在卡表中哪一个表项中）。所以G1维护记忆集的模式应该是：一个全局的卡表、每个region各自的hashtable记忆集。明显内存占用相比于其他垃圾回收器高了很多，根据经验，G1至少要耗费大约相当于java堆容量10%到20%的额外内存来维护收集器工作。

5、使用原始快照（SATB）防止对象消失问题的发生，保证用户线程和垃圾收集线程互不干扰。与此同时，每个region维护了两个名为TAMS的指针，这两个指针之中的内存区域用于给用户线程在垃圾收集过程中分配对象使用，垃圾收集线程会默认这块内存区域中的对象是存活的。

6、延迟可控的情况下，使吞吐量尽可能的高，是G1回收器的目标。

**工作过程**

1、Minor GC：过程中会停止应用进程的执行，也就是”stop the world“

1. 扫描根，从GC Roots开始扫描对象图。
2. 更新记忆集Rset，由于G1更新引用采用类似消息队列的机制，将更新的情况写入队列（dirty card queue）中，然后异步的进行处理，所以使用Rset之前需要检查消息队列，是否还没有更新完。
3. 处理记忆集Rset，更新完Rset之后，就可以使用Rset中的引用作为GC Roots了。
4. 复制对象，将Eden区存活的对象复制到Survivor区中空的内存分段中，就和普通的复制算法一样，只不过是采用分区算法执行的。
5. 处理引用，处理Soft、Weak、Phantom、Final、等引用。

2、混合回收过程：

1. 初始标记：仅仅是标记一下GC Roots能直接关联到的对象，并且修改TAMS指针的值，让下一阶段用户线程并发运行时，能正确地在可用的region中分配新对象。需要停顿线程，耗时很短，而且是借用MinorGC的时候同步完成的，所以实际没有额外的停顿。

2. 并发标记：从GC Roots开始对堆中的对象进行可达性分析，此阶段耗时较长，但可与用户线程并发执行。对象图扫描完成以后，还要重新处理SATB（原始快照）记录下的再并发时有引用变动的对象。

3. 最终标记：对用户线程做另一个短暂的暂停，处理并发阶段结束后仍遗留下来的最后那少量的SATB记录。

4. 筛选回收：负责更新region的统计数据，对各个region的回收价值和成本进行排序，根据用户所期望的停顿时间来指定回收计划，可以自由选择多个region构成回收集，把回收的region中存活的对象复制到空的region中，再清理整个旧的region空间。此部分操作涉及存活对象的移动，必须暂停用户线程，由多条垃圾收集线程完成。

3、Full GC：如果上述方式不能正常工作（清理的速度跟不上内存分配的速度），G1会停止应用程序的执行，并启用Serial GC，使用单线程独占式的垃圾回收，对整个对进行回收。

**对比CMS**

1、优点：收集算法更有发展潜力，从整体来看是标记压缩算法，局部来看是复制算法，减少内存碎片的产生；优先选取价值最大的region进行回收，回收更灵活有效；

2、缺点：垃圾收集产生的内存占用和程序运行时的额外执行负载都比CMS要高。G1中的卡表结构更加复杂，且每个region都需要维护卡表，内存占用很高，而CMS只需要维护老年代到新生代的跨代引用，只有一个卡表，因为新生代对象具有朝生夕死的不稳定性，引用频繁变化，所以没有维护新生代到老年代的跨代引用。CMS使用写后屏障来维护卡表，G1除了使用写后屏障（卡表结构更复杂，维护更繁琐）维护卡表之外，为了实现原始快照算法，还需要使用写前屏障来跟踪并发时指针的变化情况。相比于增量更新算法，原始快照能够减少并发标记和重新标记阶段的消耗，避免CMS那样在最终标记阶段停顿时间过长的缺点，但是在用户程序执行过程中会由于跟踪引用变化带来额外的负担。CMS的写屏障是直接同步的操作，而G1是使用类似于消息队列的结构，把写前屏障和写后屏障中要做的事情都放到队列里，再异步处理（因为执行消耗的资源大）。

**怎么选**

​	在小内存应用上CMS的表现大概率仍然会优于G1，而在大内存应用上G1则大多能发挥其优势，优劣势的Java堆容量平衡点通常在6GB到8GB之间。



# Java的NIO

## 1、Channel究竟是什么，有什么用？

​	Channel是否就是封装了输入输出流的一个对象？它的内部是否就有缓冲？因为如果它的内部实现就是网络通信的话，应该会有一个缓冲区用来接收客户端发来的信息？



## 2、Buffer存在的意义是什么？

​	Buffer是不是就相当于一个缓冲的数组？只是为了面向对象的编程思想，把它专门抽象成了一个Buffer对象？我觉得是这样。



## 3、非阻塞IO是如何确定客户端传输来了数据的？

​	是否是为每个socket创建一个本地缓存，当从网卡上接收到发给这个socket的数据时，存到对应的缓存中，并且设置标识为待处理的socket？



## 4、读取一个Socket，究竟是从哪里读取的？是从网卡实时接收，还是先存到本地，再从本地读取？



## 5、什么是NIO？为什么NIO要比BIO效率高？



## 6、多路复用IO：select、poll、epoll有什么区别？

### select

原理：应用程序监听多个socket，每次调用select，都需要将当前监听的所有socket复制到内核态，由操作系统来查看是否有IO操作，当出现IO操作时，操作系统将这些socket做上标记，然后复制回用户态。在用户态中仍需要遍历全部的socket才能找出其中待处理的socket。

缺点：

* 每一次调用都需要将所有的socket传入内核态，并且返回给用户态，内核态和用户态处理的时候都需要遍历，在处理的socket很多时开销很大。
* 最多只支持1024个socket连接。
* 水平触发方式，如果一个socket用户处理时没有完全处理完，那么接下来的每次select调用都需要传递再次传递这个socket，直到处理完毕。

### poll

原理：和select基本一致，只是每次传递给内核时不再使用数组，而是使用链表，解决了最多只支持1024个socket的问题。

### epoll

原理：

​	调用时不再需要将socket数组传递到内核态，而是在内核态维护一个红黑树，用于存放所有的socket，并且也不需要将所有的socket传递回用户态，而是在内核态维护一个就绪链表，使用回调机制，当某个socket上有IO时就会触发回调函数，将这个socket放入就绪队列中，只需要将这个就绪链表复制给用户态就可以了。epoll调用分成了三个系统调用，其中epoll_create()是创建红黑树和就绪链表，epoll_ctl()向内核态中的红黑树对象添加监听的socket，红黑树会对这些socket自动去重，epoll_wait()收集发生了IO的socket，也就是获得内核态返回的socket链表。

​	除此之外，epoll还有两种模式：LT模式和ET模式。

* LT模式：水平触发，某次epoll_wait()函数返回后，应用程序对就绪的socket操作时没有读取完数据（缓冲区大小不够等原因），那么应用程序调用epoll_wait()时，操作系统还会将没处理完的socket放入到就绪链表中。
* ET模式：边缘触发，调用epoll_wait()返回的socket只会返回一次，也就是说，类似于上面的那种情况时，下次调用epoll_wait()时，不会返回前面返回却没有处理完的socket，除非这个socket上又发生了新的IO事件。

		为什么使用ET模式？因为在LT模式下，如果有大量的不同socket上的IO事件需要处理，但很多socket上的IO都需要多次处理才能处理完，那么这些socket需要在接下来的每一次调用epoll_wait()时，都传递一遍到用户态中。这样就导致处理的效率不高。
		
		但说是这么说，实际上我还是感觉ET模式下只处理一次后续不再理会这种方式效率只是短暂的高，因为被忽视的socket上的内容你迟早都得处理，除非你做的处理是一次就将网络IO操作执行完毕。总的来说，各有各的好，看程序员怎么使用吧（可能）。



# 设计模式

## 1、策略模式和简单工厂模式有何区别？

执行权不同：

* 简单工厂模式是创建所需要的对象，将执行权交给客户端。

* 策略模式是将执行权给封装起来了，在类的内部执行方法，对外只暴露一个调用接口，将结果返回。

控制点不同：

* 简单工厂模式是在工厂类中编写创建对象的代码，也就是说如果有多个类，由工厂类来判断选择创建哪一个类。
* 策略模式则是将判断交给了客户端，由客户端来判断要使用哪个策略，所以本质上还是加重了客户端代码的复杂程度。



​	为了解决策略模式带来的弊端，同时利用策略模式的优点：不需要调用者参与过多的方法调用，只需要指定使用哪个策略，剩余的由策略对象来完成。可以将简单工厂模式和策略模式结合使用，使用简单工厂模式封装选择策略的判断方法，这样调用者就无需做大量判断。



## 2、如何理解依赖倒转原则？

​	面向接口编程？

​	依赖倒转原则：抽象不应该依赖细节，细节应该依赖抽象。

​	我的理解：当我们在开发软件的时候，如果要设计两个相互依赖的模块，在这两个模块的抽象类中，应该要依赖另一个模块的抽象类，而不应该依赖具体的实现类，这样能够松耦合。



## 3、如何理解外观模式完美体现了依赖倒转原则和迪米特法则？

​	迪米特法则好说，客户端只依赖于外观类，而外观类再调用其他的类来实现相应的功能。但它怎么完美体现了依赖倒转原则？我的理解是这样：客户端依赖于外观类来实现具体的操作，相当于是依赖于抽象？因为这个外观类就是用来完成某一方法的，如果有一些细节需要改变，不会影响到客户端。



## 4、抽象工厂模式和工厂方法模式的区别？

​	我的理解：抽象工厂模式一个工厂代表一个类别，也就是一个工厂可以生产多个不同的产品。而工厂方法模式是一个工厂只生产一种产品。工厂方法模式增加一个具体的产品，需要增加一个工厂类。

​	准确来说：抽象工厂方法有多个抽象产品类，一个抽象工厂类，每个实现的工厂类需要能够制造出多个产品（实现多个制造抽象产品的方法）。工厂方法模式有一个抽象产品类，一个抽象工厂类，每个实现的工厂只需要制造一个产品。



## 5、适配器模式和代理模式的区别？适配器模式的思想是什么？

​	目的不同：适配器模式解决的问题是接口功能相似，但调用却不相同的情况。而代理模式一是不让原对象被直接调用，二是可以增强功能。

​	**大话设计模式中：**系统的数据和行为都正确，但接口不符时，我们应该考虑用适配器，目的是使控制范围之外的一个原有对象与某个接口匹配。适配器模式主要应用于希望服用一些现存的类，但是接口又与服用环境要求不一致的情况。




## 6、适配器模式的具体使用？

​	当你的系统需要接入其他系统，而又不能修改这个其他系统的代码，且这个其他系统实现的接口和你需要的接口功能相同，但调用方法不一样，这时候需要使用适配器模式将这个其他系统的接口转成你的系统中需要的接口。



## 7、单例模式和静态工具类的区别？

​	如何理解大话设计模式中：实用类不保存状态，仅提供一些静态方法或静态属性让你使用，而单例模式是有状态的？
​	因为单例模式是用于创建对象的，创建的对象就有自己的状态，在不同的时刻状态可能发生改变，而静态类没有这样的特征。




## 8、设计模式原则有哪些？

​	单一职责原则、开闭原则、依赖倒转原则、里式替换原则、迪米特法则、合成复用原则、接口隔离原则。



## 9、装饰模式和代理模式有什么区别？

​	这两个模式确实在使用上是非常相似的，都是可以对原有类的功能进行扩展。但两个模式最大的区别我觉得就是代理模式一般是用于**对访问进行控制**，一般情况下，我们不能直接访问原有类，所以需要使用代理类来进行操作，进行功能的增强和访问控制。



## 10、设计模式分为哪三大类？

### 创建型

### 结构型

### 行为型



# Redis

## 1、Redis持久化策略有哪些？有什么区别？

### RDB

#### 特点

1、在指定的时间间隔内将内存中的数据及快照写入磁盘，恢复时是将快照文件直接读取到内存里。

2、Redis会单独创建一个子进程来进行持久化，先将数据写入到一个临时文件中，待持久化结束了，再用这个临时文件替换之前持久化的rdb文件。

3、主线程不进行任何IO操作，确保了极高的性能，如果需要进行大规模数据的恢复，且对于数据恢复的完整性不是很敏感，rdb比aof更加高效。

4、最后一次持久化后的数据可能丢失。

#### 配置

1、通过dbfilename属性配置rdb文件的名称。

2、通过dir属性配置文件位置。

3、save属性配置写操作，默认是1分钟内进行了1万次更改，5分钟内进行了10次更改，15分钟内进行了1次修改时就进行rdb持久化。

4、rdbcomparession属性控制压缩rdb文件，设置属性值为yes，表示开启压缩存储。使用lzf算法进行压缩。

#### 优点

1、适合大规模的数据恢复。

2、对数据完整性和一致性要求不高更适合使用。

3、节省磁盘空间。

4、恢复速度快。

#### 缺点

1、持久化时是存入临时文件中，大致2倍的膨胀性需要考虑。

2、虽然Linux进程采用了写时拷贝技术，但是如果数据量庞大的话还是比较消耗性能。

3、一定时间间隔做一次备份，如果redis意外挂掉的话，就会丢失最后一次快照后的所有修改。



### AOF

#### 特点

1、以日志形式来记录每个写操作（增量保存），将所有执行的写指令记录下来。

2、redis重启时根据aof文件的内容重构数据，即将aof文件中的写指令全部执行一遍来完成数据恢复操作。

3、客户端的写命令会被追加到aof缓冲区中，再根据aof持久化策略将aof缓冲区内的写命令同步到磁盘中的aof文件中。

4、aof文件大小超过重写策略或手动重写时，会进行重写操作，压缩aof文件大小。

5、redis4.0版本后的重写，实质上就是把rdb的数据快照以二进制的形式附在新的aof的头部，作为历史数据替换掉写命令。

6、重写触发机制，redis会记录上次重写时aof文件的大小，默认配置是当aof文件为上次重写后大小的一倍且文件大于64m时进行重写。

7、重写也是创建子进程来进行重写，同时redis还有另一个缓冲区：aof_rewrite_buf，重写时用户的写请求会同时写入这个缓冲区，子进程再将这个缓冲区内的写命令写入重写后的aof文件，保证在进行重写时用户的写请求不丢失。

8、子进程重写aof文件也是先写入临时文件中，然后再进行替换。

#### 属性

1、appendfsync属性配置aof同步频率，always表示每次写入都会立刻计入日志，性能较差但保证数据完整性；everysec表示每秒进行同步，如果redis服务器宕机，本秒的数据可能丢失；no表示redis不主动进行同步，把同步时机交给操作系统。

2、no-appendfsync-on-rewrite控制是否不在每次同步时将aof缓存中的写命令写入磁盘，yes表示只写入缓存，降低数据安全性，提高性能；no表示每次同步还是写入磁盘上的aof文件中，数据安全，但是性能会降低。

3、auto-aof-rewrite-min-size表示重写的基准值，默认为64m，只有文件大于这个值才开始重写。

#### 优点

1、备份机制更稳健，丢失数据概率更低。

2、可读的日志文本，通过操作aof文件，可以处理误操作。

#### 缺点

1、占用的磁盘空间更多。

2、恢复备份速度慢。

3、每次读写都同步的话，有一定的性能压力。

4、存在个别bug，造成不能恢复。



### 问题

1、rdb和aof同时开启，redis听谁的（根据谁来恢复数据）？系统默认读取aof的数据，因为aof文件出现丢失的概率很小。



## 2、Redis有哪些数据类型？详细说说？





# MySQL

## 1、聚集索引是什么？

​	MySQL低层存储数据的结构就是一个聚簇索引，将索引和数据结合在一起。



## 2、MySQL数据库插入数据时究竟是如何插入的？

​	得要根据具体的存储引擎来判断如何插入数据，如果是innodb存储引擎，则是先向聚簇索引中插入新数据，然后再向其他二级索引中插入新数据。



## 3、character_set_connection的作用是什么？

​	在已经有character_set_client和character_set_results来分别接收和响应客户端请求的情况下，character_set_connection的作用是什么？为什么不能直接从character_set_client转为内部操作字符集？



## 4、MySQL中的一页（数据页）是物理内存页吗？

​	MySQL中的一页大小是16kb，不知道现在的操作系统物理内存一页大小是多少。

​	应该不是物理内存页，物理内存页的大小应该是4kb（和操作系统有关吧）。



## 5、MySQL的数据是如何存储的？

​	为什么尚硅谷视频中，在116集中说，如果表中的数据都在一个数据页中，不按照主键查询时，就要顺序遍历单链表？并且老师还说想找到很大的连续内存是很难的，所以要使用单链表的形式组织数据。

​	难道是数据页中存储的并不是原始数据，而是数据的一些信息？每一行的一些信息，使用时还要再去读取磁盘，那不是太麻烦了？

​	MySQL使用innodb存储引擎时，使用的是聚簇索引来存储数据，真实的数据存储在叶子节点上。



## 6、为什么二级索引的非叶子节点上也要存储主键值？

​	是为了确保二级索引非叶子节点中目录项的唯一性，因为二级索引可能不是具有唯一性的，所以可能造成很多二级索引的列值是相同的，导致插入的时候不知道应该插入到哪个节点上，所以我们需要加上主键值以区分目录项，当目录项相同时，按照主键值大小来进行排序，这样的话，插入操作就会顺利很多。



## 7、最左前缀原则是什么？

​	在使用联合索引时，如果查询的条件不包含创建索引时最左边的列，即使你的查询条件包含了联合索引剩下的所有列，也用不上这个联合索引。



## 8、为什么创建存储函数时会报错？该怎么解决？

​	这是因为数据库开启了慢查询日志bin-log，主从复制中，主机会将写操作记录在bin-log中。从机读取bin-log日志，执行语句来同步数据。如果使用函数来操作数据，可能会导致从机和主机的数据不一致（个人理解），导致从机和主机操作时间不一致（不是很理解这个），所以为了保证一致性，MySQL默认不开启创建函数设置。

​	执行 set global log_bin_trust_function_creators=1; 语句解决问题。



## 9、浮点数和定点数有哪些区别？什么时候使用浮点数？什么时候使用定点数？

​	区别：

* **存储格式不同： **浮点数存储时会有精度缺失，因为其低层是以二进制数值形式存储的（应该是IEEE754标准）；而定点数不会产生精度缺失，因为定点数在MySQL中是以字符串形式进行存储的。
* **存储空间不同：**浮点数float和double类型都有固定的存储大小，float占用4字节，double占用8字节；定点数存储大小由精度M和标度D决定所占用字节为M+2，不是固定的。

		浮点数相对于定点数的优点是：在同样的存储空间下，浮点数所表示的数值范围要大于定点数。适用于取值范围大，又可以容忍微小误差的场景，比如科学计算场景（允许误差的情况下）。
		
		定点数相对于浮点数的优点是：精确度高，因为是使用字符串进行存储的，能够保证数据的精确性，适合于对精度要求极高的场景，比如涉及金额计算的场景。



## 10、TIMESTAMP类型和DATETIME类型有什么不同？该如何选择这两种类型？

​	区别：

* timestamp存储空间比较小（4字节），表示的日期时间范围也比较小，而datetime类型占据8个字节。
* 低层存储方式不同，timestamp低层存储的是毫秒值，距离1970-1-1 0:0:0 0毫秒的毫秒值，相当于java中System.currentTimeMillis()方法返回值。datetime低层存储的也是整型数值，但不是毫秒值（不确定）。
* 两个日期比较大小或日期计算时，timestamp更方便、更快。
* timestamp和时区有关。timestamp会根据用户的时区不同，显示不同的结果。而datetime则只能反映出插入时当地的时区，其他时区的人查看数据必然会有误差的。



​	开发中使用最多的时间类型就是datetime，因为这个数据类型包括了完整的日期和时间信息，取值范围更大，使用起来比较方便。

​	一般存注册时间、商品发布时间等，不建议使用datetime存储，而是使用时间戳timestamp，因为datetime虽然直观，但不便于计算。



## 11、为什么Innodb存储引擎中建议使用varchar类型？

​	课件中说的是innodb数据表中的行存储格式并没有区分固定长度和可变长度列，所有数据行都使用指向数据列值的头指针。这里我不太理解，复习到行格式的时候再看看。



## 12、什么是数据字典？

​	Innodb中用于存储一些元数据的内部系统表，这些表也被称为数据字典。



## 13、改变表的存储引擎，会造成什么影响？

​	如果一张表刚开始使用的存储引擎是innodb，在存储了一些数据之后，我把存储引擎改成了myisam存储引擎，那么低层存储数据的文件会不会改变？

​	经过我的测试之后发现：底层的存储文件会被改变。

​	在MySQL5.7版本下实验的结果（修改存储引擎之前）：

![image-20221113222334829](D:\文档\学习笔记\学习疑问.assets\image-20221113222334829.png)

​	修改之后：

![image-20221113222418632](D:\文档\学习笔记\学习疑问.assets\image-20221113222418632.png)



## 14、采用自增主键和随机主键对性能的影响有多大？





## 15、目录项是怎样建立的？

​	是只有数据页建立的时候分组建立目录项，还是包括索引页在内，都是分组建立目录项？

​	应该是都分组建立目录项，分组的原因是减少冗余，提高磁盘利用空间，进而提高查询效率，建立目录页的时候也可以使用分组的形式减少冗余，这是完全可行的。



## 16、对比哈希索引和B+树索引，说明为什么innodb不使用哈希索引？

​	哈希索引进行等值查询的效率非常高，在没有大量重复索引值的情况下，能够达到O(1)级别，是B+树索引无法企及的。

​	但哈希索引的一些缺点导致数据库索引一般不会采用哈希索引：

* 哈希索引无法适应范围查询，进行范围查询的时候，时间复杂度会退化为O(n)级别。而B+树的树形结构，包括它叶子结点的链表设计，都使得它在进行范围查询的时候依旧高效，保持O(log2n)的时间复杂度。
* 哈希索引的存储是没有顺序的，在进行Order by排序的时候，哈希索引还要对数据进行排序。
* 对于联合索引，hash值是将联合索引键值合并后计算的，无法对单独的一个键或者几个索引键进行查询。
* 对于等值查询来说，通常hash索引的效率更高，不过也存在一种情况，就是索引列的重复值如果很多，效率就会降低。这是因为遇到哈希冲突的时候，需要遍历桶中的行指针来进行比较，找到查询的关键字，非常耗时。所以hash索引通常不会用到重复值多的列上，比如列为性别、年龄的情况等。
* 哈希索引不支持模糊查询，因为是将数据通过哈希算法计算出hash值后，再映射到哈希表中。



## 17、对比B树和B+树，说说两者的不同之处，为什么B+树更适合文件索引系统？

不同之处：

* B+树有k个孩子的节点就有k个关键字，而B树是孩子节点的数量=关键字+1。
* B+树中非叶子节点的关键字也会同时存在于子节点中，并且是子节点中最大或最小的关键字。而B树中子节点没有父节点的关键字。
* B+树中非叶子节点仅用于索引，不用于存储数据，跟记录有关的信息放在叶子结点中。而B树中，非叶子节点即用于索引，也保存数据。
* 所有关键字都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小顺序链接。



为什么B+树更适合文件索引系统？主要原因是**B+树的中间节点不存储数据。**

* B+树查询效率更稳定，所有的数据都在叶子节点上，每次查询都要找到叶子节点。
* B+树查询效率更高，因为通常B+树比B树更矮胖。同样的磁盘页大小，由于B+树中间节点不存储数据，所以它的中间节点能够存储更多关键字，也就有更多子节点，就更加矮胖。
* 在查询范围上，B+树的效率也比B树高。因为B+树所有的关键字都出现在B+树的叶子节点中，叶子节点之间又有指针相连，数据也是有顺序的，这使得范围查找可以通过指针连接查找。而B树中，由于某些数据可能不在叶子节点上，在中间节点上，进行范围查询的时候需要使用中序遍历才能完成范围的查找，效率要低得多。



## 18、Innodb存储引擎中为什么在页的基础上还要提出区、段、表空间的概念？

​	**为什么要有区：**因为在范围查询的时候可能会遍历到相邻的页，如果两个页在物理磁盘上的位置是随机的话，就会造成随机IO，导致效率很低。为了防止这种随机IO现象，使用区的概念，一个区就是在物理位置上连续的64个页，占用大小是1MB，为某个索引分配空间的时候就不再按照页为单位分配了，而是按照区为单位分配，虽然可能造成一些空间的浪费，但是消除了很多随机IO。

​	**为什么要有段：**对于范围查询，其实是对B+树叶子节点中的记录进行顺序扫描，如果不区分叶子节点和非叶子节点的话，一个区的大小是有限的，就造成可能这个区装了很多非叶子节点，导致范围查询还是要进行随机IO（我的想法）。所以Innodb对B+树的叶子节点和非叶子节点进行了区别对待，分为叶子节点区和非叶子节点区。存放叶子节点区的集合就算是一个叶子节点段，反之称为非叶子节点段。



## 19、Innodb如何解决这种情况：刷新文件到磁盘时，文件刷新到一半时，服务器突然断电了。

​	通过判断页的文件头和文件尾中的checksum来判断当前页的刷新是否出了问题，如果是上述情况，则文件头和尾的checksum结果不相同，需要进行重新传输或者特殊处理。



## 20、什么是碎片区？为什么要有碎片区？

​	碎片区是用于存储不同类型的页的一块区，其中可以存储数据页、索引页等，而一般的区都是专门存储某一类型的页。

​	以完整的区为单位分配给某个段对于数据量较小的表来说太浪费存储空间了，因为一个区的大小是1MB，如果直接就以区为单位分配，那么再小的表也需要最少2MB空间，一个叶子节点段和一个非叶子节点段。为了避免这种情况，提出了先以碎片区存储某个段的页面，当某个段的页面数量达到32个碎片区页面后，再单独分配一个区给这个段。



## 21、什么时候子查询能够转换成连接查询？连接查询和子查询哪种方式更加高效，为什么？

​	第一个问题问的很宽泛，其实提出的不是很好。我觉得如果子查询是不同的表数据，那么就可以采用连接查询的方式替代子查询。

​	子查询的效率不高，因为

​	①执行子查询时，MySQL需要为内层查询语句的查询结果建立一个临时表，然后外层查询从临时表中查询记录。

​	②子查询的结果集存储的临时表，不论是内存临时表还是磁盘临时表都不会存在索引，索引查询性能会收到一定的影响。（join会产生临时表吗？如果会的话join是不是也有这个缺点？为搞清楚这点，我提出了第25个问题）。

​	③对于返回结果集比较大的子查询，其对查询性能的影响也就越大。



## 22、为什么带有IN的子查询会是相关子查询？

​	比如：

```mysql
select * from s1 where key1 in (select key1 from s2 where key1 = 'a')
```

​	因为这个SQL语句会被优化器优化成exist形式的SQL查询，将当前s1每条记录的key1传入到第二个子查询中，就变成了相关子查询了（大概是这样吧）。



## 23、什么是覆盖索引？

​	在使用二级索引查询时，如果要查询出来的所有字段都在当前索引中存在，比如：

~~~mysql
#key1上有一个普通索引
select key1 from s1 where key1 = 'a'
~~~

​	这样不需要回表操作的查询，这样的操作就称为覆盖索引。



## 24、为什么表连接的时候要使用小表连接大表？

​	因为要使用小表做驱动表，在没有索引的情况下，MySQL会对驱动表做优化，不是每次单独取出一个记录来和被驱动表的所有记录进行匹配，这样的话就可能会进行大量重复的IO，例如当前的记录取出了被驱动表的所有记录一次，而下一个记录还要再全部取出来一遍，所以，MySQL使用一个缓存，一次读取多条驱动表中的记录，然后取出被驱动表的记录时，和缓存中的所有记录匹配一次，这样就减少了很多不必要的IO。因为缓存大小是有限的，所以驱动表越小，IO的次数就越少。



## 25、连接查询会产生临时表吗？

​	连接查询不会产生临时表，join连接的低层逻辑是取出驱动表的一条记录，如果没有索引的话，就取出被驱动表的所有记录进行on条件的匹配，然后再进行where条件的过滤，不是将两个表连接之后再进行where条件的过滤，在这个过程中，没有产生临时表。



## 26、什么是索引条件下推？

​	类似于这样一条SQL：

~~~mysql
#key1上建立了索引
select * from s1 where key1 > 'z' and key1 like '%a';
~~~

​	我们直观的会认为执行流程是这样的：先使用索引查询第一个条件，然后把所有满足第一个条件的叶子节点都进行回表操作，取出完整的一条数据，然后再比较第二个条件，选出最终的结果。

​	如果经过第一个条件过滤后还剩下1万条数据，而再经过第一条数据查询后还剩下100条数据，按照刚刚所想的流程来走，就可能造成1万次随机IO，性能不理想。

​	但我们可以发现，第二个条件经过第一个条件过滤后的索引中也是可以进行判断的，如果我们先经过第二个条件的判断，再进行回表操作的话，可能就只有100次随机IO，效率大幅提升。

​	索引条件下推的好处：一个查询语句的条件中，使用到了一个字段，在联合索引（一般情况下是联合索引）中有这个字段，但是这个字段使用 了模糊查询或其他情况导致索引中的这部分失效了，使用索引条件下推可以在回表之前进行一个过滤，减少回表的次数。



## 27、什么是幻读现象？

​	为什么尚硅谷老师讲的和之前学的不太一样，幻读是指读入了新增的记录？那么究竟哪个是真的？

​	我百度了一下，发现老杜讲的好像不对，应该是现在这个版本比较对。



## 28、union和union all有什么区别？为什么建议使用union all？

​	使用union时，会生成一个临时表，这个临时表是由union的表拼接而成，然后会对这个临时表进行操作，去除掉相同的行。而union all则不会对union后的数据进行去重。

​	因为union要对临时表进行操作，而临时表中无法使用索引，且生成和维护临时表也需要开销。所以建议使用union all。



## 29、同样是要写到磁盘上，为什么不直接修改数据库文件，而是写入到redo日志中？redo日志中都记录了什么内容？

​	写入到数据库文件中的缺点：

* 由于Innodb存储引擎存储数据是以页为单位来存储和读取的，也就是说，查询和修改后的刷盘操作，都是一次操作一个页，如果每次修改完要修改磁盘上的数据库文件的话，有可能只修改了一个页中很小的一部分，但是却要把整个页面都刷新回磁盘中，代价太高。
* 还是上面那条的原因，数据库以页为单位从磁盘中读取和存入数据，就可能造成很多的随机IO，导致效率非常低。

		如果是写入redo日志的话，就可以避免大量的随机IO，并且每次只要把事务的操作写入到redo日志中就行了。
		
		redo日志中记录的是对物理磁盘上数据进行的操作。



## 30、redo log 和bin log的区别是什么？

​	redo log跟bin log的区别是：redo log是存储引擎层产生的，而bin log是数据库层产生的。假设一个事务，对表做十万行记录的插入，在插入过程中，一直不断的往redo log顺序记录，而bin log不会记录，直到这个事务提交，才会一次写入到bin log文件中。



## 31、什么是mtr？怎么理解一个mtr可能包含一组redo日志？

​	MySQL把对底层页面中的一次原子访问的过程称为一个Mini-Transaction，简称mtr。

​	一个mtr有可能对低层的页面进行多个操作，比如插入记录时如果没有按照主键递增的顺序进行插入，此时的插入操作造成了低层B+树的页分裂等操作，这时候就会有多个redo记录下这些操作，所以说一个mtr可能包含一组redo日志。



## 32、为什么undo log也会产生redo log？

​	因为将操作写入undo log的过程中也需要保障一致性，所以需要将修改undo log的操作也先记录进redo log中。

​	再次提问：为了保障事务的一致性，由于更新数据库的操作可能会造成随机IO，所以先写入redo log可以理解，但写入undo log不是和redo log一样，很少随机IO吗，那为什么undo log也会产生redo log？

​	并不是如此，之前我一直以为写入undo log中和写入redo log中是一样的，都是写入文件而已，但是undo log却是以回滚段和undo页的形式存在的



## 33、脏写、脏读、不可重复读、幻读现象分别是什么？

​	脏写：两个事务同时对一条记录进行修改，对方事务还没有提交，当前事务修改了这条记录并且提交了，而随后对方事务也进行了记录的修改并提交，且覆盖掉了前一条事务的修改，造成了这样一种现象：命名我操作的事务进行了修改，但却看不到我的修改。

​	脏读：对方事务还没有提交，当前事务就读到了被修改的数据，但随后对方事务可能进行回滚，所以当前事务读到的数据是脏数据，并不是实际的数据。

​	不可重复读：当前事务先读取了某一条记录，随后这条记录被别的事务修改并提交了（只有读未提交隔离级别下不用提交也可以造成），当前事务再一次读取同一条记录，读取到的结果却和第一次不同了，也就是说，在一个事务中，发生了读取数据不一致的行为。

​	幻读：当前事务对数据进行修改，随后其他事务对数据进行了插入操作，导致当前事务发现表中存在还未被修改的记录，就好像发生了幻觉一样。比如一个事务对一个表执行条件查询 select * from table where id = 3 ，随后另一个事务在这个表中插入了id为3的记录。



## 34、关于二级索引中进行操作产生的疑问

​	如果在一个事务插入了一条记录，然后造成了二级索引新加了一条记录，这时候另外一个事务对二级索引进行了查找，如果要查找这条记录，这时候MySQL是如何处理的？

​	每个二级索引的页面的页面头中都有记录一些信息，其中针对此情况起到作用的是PAGE_MAX_TRX_ID属性，该属性代表对该页面做改动的最大的事务id，所以第二个事务操作的时候需要检查二级索引页面中的这个属性，如果最近一次修改此页面的事务是已提交页面的话则可以进行操作，否则的话就去聚簇索引中查找这条记录所对应的行信息，再做一些校验。



## 35、在MVCC中如果一个事务进行delete操作，但还没有提交，那么别的事务来查询，是一个怎样的流程？

​	首先，事务中的删除操作并不是真正的删除掉了这条数据，而是将数据行格式的delete_bit设置为1，然后等待purge线程来进行回收，如果删除操作的事务还没有提交，那么这条记录是肯定不会被清除的，而未删除的版本也在undo日志中进行了记录。所以此时别的事务来查询，也是按照快照读的流程走，最终找到可以读的历史版本。



## 36、redo日志两阶段提交是什么？为什么要使用两阶段提交？

​	redo日志的两阶段提交是指为了保证redo日志和bin-log日志的一致性，在刷盘bin-log缓存的前后将redo日志的刷盘过程分为两步：prepare阶段和commit阶段。

​	使用两阶段提交是为了确保redo和bin-log中数据的一致性。

![image-20230313113155702](D:\文档\学习笔记\学习疑问.assets\image-20230313113155702.png)



## 37、bin-log格式有何区别？

​	statement格式中就是记录所执行的一条SQL语句，而row格式记录的就是所影响的行信息。

​	比如update操作影响到了很多行的时候statement格式就只会记录这条update语句，而row格式就会记录具体哪些行做了哪些修改。

~~~MySQL
update class set monitor = 5 where id > 10;
~~~

​	在statement格式中就只会记录这一条SQL语句，而row格式中会记录下来所有被改变的行，假如此时class表中id > 10的数据有100条，那么这100条全部都会被记录下来。



## 38、进行全表扫描的update时，会将所扫描到的所有记录都锁定吗？

### read-committed隔离级别下	

​	在read-committed隔离级别下，我的测试结果如下，事务A：

![image-20221126150102844](.\学习疑问.assets\image-20221126150102844.png)

​	事务B：

![image-20221126150126581](.\学习疑问.assets\image-20221126150126581.png)

​	为什么事务B仍然查出来了，明明事务A使用的是全表扫描。

​	但如果事务B执行如下：

![image-20221126150519860](.\学习疑问.assets\image-20221126150519860.png)

​	则会进入等待中，这是什么原理？还是没搞清楚，以后再看看。



### repeatable-read隔离级别下

​	然而在repeatable-read隔离级别下，上面例子的两个操作都会阻塞住，说明for update确实是将扫描到的所有记录锁住了。

**另一种情况：**for update加锁的行使用了索引

​	事务A：

![image-20221126165135691](.\学习疑问.assets\image-20221126165135691.png)

​	事务B：

![image-20221126165209842](.\学习疑问.assets\image-20221126165209842.png)

​	可以看到，事务B并没有被阻塞，说明for update这次上的是行锁。

​	然而如果事务B按照非索引字段进行查询，则会进入阻塞：

![image-20221126165438447](.\学习疑问.assets\image-20221126165438447.png)

​	这是什么原因造成的呢？我的推测是for update和for share操作都会对遍历到的记录加锁，所以上一种情况下不使用索引的for update将所有扫描过的记录都锁住了。而这种情况值扫描了一个记录，所以只锁住了一条记录，当使用索引的for share时，找到别的记录就不会被阻塞了。而不使用索引的for share，也需要进行全表扫描，最终扫描到for update的那条记录，就会阻塞住。



**再一种情况：**

​	事务A：

![image-20221126171001049](.\学习疑问.assets\image-20221126171001049.png)

​	事务B：

![image-20221126171016243](.\学习疑问.assets\image-20221126171016243.png)

​	验证了索引覆盖的情况，第二次查询由于只需要id字段，所以直接在二级索引里查找并锁定二级索引就行了。



## 39、为什么undo只是逻辑上将数据库恢复到原来的样子？

​	undo日志记录的是逻辑上恢复的操作，比如事务中进行了insert，那么undo日志中记录的就是一条delete语句，但如果在插入数据的过程中进行了页分裂或其他改变底层聚簇索引的操作，使用undo回滚的时候并不会将物理结构修改回原来的样子。

​	为什么不进行物理的恢复：因为在多用户并发系统中，可能会有多个并发事务同时执行，如果多个事务同时对一个表中的不同记录进行修改，如果是将数据物理的恢复成事务之前的样子，当一个事务回滚的时候，改变了底层的物理结构，会影响到同时在进行操作的其他事务。



## 40、MySQL可重复读隔离级别是如何解决幻读问题的？彻底解决了幻读问题吗？

​	通过MVCC+临键锁的方式解决，临键锁锁住记录之间的间隙，防止别的事务进行插入，MVCC执行快照读，避免读取到与当前事务并发执行的事务插入的数据。

​	我认为是没有彻底解决幻读问题的，因为要完全避免幻读问题，就要将所有可能读到的间隙锁起来，这样的话造成锁太多，降低并发度。如果不在乎并发度的话，是可以解决幻读问题的。

​	

## 41、为什么交错锁模式从bin log重播SQL语句时是不安全的？

​	首先，交错锁模式是自增锁的一种模式，它有可能造成插入的行生成的值不是连续的。

​	然后，应该要从bin log日志恢复数据的角度来思考为什么是不安全的，有些忘了，先留个悬念。

**redo、undo、bin log记录的情况**：

* redo记录的是物理的操作，比如对磁盘上的哪个页进行了怎样的操作。
* undo记录的是逻辑的操作，比如插入一条记录，undo中记录的就是删除这条记录的操作，并不能物理的恢复。
* bin log记录的情况和其使用的格式是相关的，如果使用statement格式，则记录执行的语句，如果使用row格式，则记录的是对物理文件中某一行的操作。同时bin log记录语句是以事件的方式来进行记录的。bin log记录的也是逻辑的操作。



## 42、元数据锁有可能带来什么问题？

​	如果事务A对一张表进行了DML操作，获取了这张表的MDL（元数据锁）读锁，然后事务B要进行DDL操作，需要获取这张表的MDL写锁，此时就需要阻塞了，在这个时候，如果事务C要对这张表进行DML操作，也是要获取MDL读锁，正常情况下，应该是可以获得的，但是由于事务B被阻塞了，此时事务C也会被事务B阻塞。



## 43、数据页中固定的最大和最小记录有什么作用？

* 在给边界加间隙锁的时候，最大和最小记录就能够起到作用了，因为间隙锁是锁住小于当前记录的间隙，所以锁住最大记录就可以防止其他事务往边界情况插入记录，比如当前最大的主键值是20，锁住最大记录可以防止插入主键值大于20的记录。
* 便于插入和删除页中的记录，因为innodb的存储结构是一个B+树，存储记录的页面中使用链表的形式组织行记录，这时候最大最小记录就相当于链表中的头尾节点，在操作的时候方便很多。



## 44、什么是隐式锁？

​	我的理解是：隐式锁是指在一个事务中进行了添加记录操作，当前事务没有提交时，虽然添加的记录没有显式的添加锁结构，但是其他事务进行操作时都会通过检查隐藏字段trx_id来确保这个记录是可以操作的。

​	具体案例：事务A在表中添加了一条记录，事务A还没有提交，此时事务B要给这条记录加锁

* 对于聚簇索引记录操作，事务B检查记录行的trx_id，如果是活跃的事务，那么给这条记录加上事务A的锁，然后再生成自己的锁，进入等待。
* 对于二级索引记录操作，检查页Page Header的PAGE_MAX_TRX_ID属性，如果这个值小于当前活跃事务的最小id，那么可以操作，否则，回表然后进行和上面一样的操作。



## 45、为什么一个事务查询数据时给数据加了排它锁，但是其他事务依然能够读取到这些数据？

​	事务A：

~~~mysql
begin;
select * from class for update;
~~~

​	事务B：

~~~mysql
begin;
select * from class;
~~~

​	因为事务B只是简单的读取数据，并没有给数据加锁。

如果事务B：

~~~mysql
begin;
select * from class for share;
~~~

则会阻塞



## 46、事务是怎样对于记录加锁的？是每锁一条记录就生成一个锁结构吗？

​	对于符合一定条件的记录，会使用同一个锁结构，具体满足以下条件：

* 在同一个事务中进行的加锁操作
* 被加锁的记录在同一个页面中
* 加锁的类型是一样的
* 等待状态是一样的



## 47、索引在什么情况下会失效？

1、查询条件中使用了计算、函数、类型转换都会导致索引失效，其中类型转换不管是手动的还是自动的，都会失效。

2、当查询条件中有范围查询时，如果是范围查询的列是联合索引中的一部分，那么即使在查询的右边还有联合索引的列，并且满足最左前缀原则，也不会使用到。

3、比如：select * from test where id > 1 and age = 20，即使联合索引是(id,age)，此时索引只会用上联合索引的前面部分，即id部分，而用不上age。

4、查询条件中使用了不等于时，索引也会失效。为何？因为不等于的范围很广，查询优化器直接判定不如直接全表扫描。

5、查询条件中使用了is not null。类似于不等于条件。

6、查询条件中使用like，并且模糊查询以%开头，此时索引会失效。

7、查询条件中的or前后存在非索引的字段（列），索引失效。

8、数据库和表的字符集最好是统一使用utf8mb4，要不然可能会由于字符转化造成索引失效。



## 48、数据库如何进行调优？

### 1、优化服务器硬件

​	服务器硬件性能直接决定这MySQL数据库的性能。

### 2、优化MySQL的参数

​	innodb_buffer_pool_size表示innodb引擎的表和索引的最大缓存；key_buffer_size表示索引缓冲区的大小；table_cache表示同时打开的表的个数；innodb_log_buffer_size表示事物日志所使用的的缓冲区。

### 3、优化数据库的结构

* **拆分表**，将冷热数据分离，比如将用户信息中不常用的数据拆分出来，放入用户详情表中。这种分解可以提高表的查询效率，对于字段很多且有些字段不常用的表，可以通过这种分解方式来优化数据库性能。
* **增加中间表**，比如有学生和班级表，班级表中有每个班级对应的班长信息，现在有一个业务要经常使用学生、班级、班长信息，可以考虑创建一个中间表，专门存放着三个信息。
* **增加冗余字段**，比如学生和班级信息是分开存放的，但是业务现在的需求是频繁的查询学生和对应的班级名称，那么我们可以在学生表中添加上班级名称这个冗余字段。
* **优化数据类型**，整数数据类型可以使用int，在数据量很大的时候，数据类型的定义，在很大程度上会影响到系统整体的执行效率，对于非负型整数，优先使用unsigned存储，因为unsigned有更大的存储空间。优先使用整数类型，对于既可以使用文本类型又可以使用整数类型的情况下，使用整数可以占用更少的存储空间，例如存储IP地址，既可以使用使用字符串，也可以使用整型。
* **优化插入记录的速度**，Innodb引擎的表可以：禁用唯一性检查、禁用外检检查、禁止自动提交；MyISAM引擎的表：禁用索引、禁用唯一性检查、使用批量插入。
* **使用非空约束**，在设计字段的时候，如果业务允许，建议尽量使用非空约束，首先如果允许存在null值，那么在innodb的行格式中就要多出一个null值列表，多占用一些存储空间。其次，在查询的时候如果可以为null，那么还要全部过滤一遍，索引效率高的前提是列的区分度大，包含`NULL`的列很难优化，而且对表索引时不会存储 `NULL` 值。如果索引字段可以为 `NULL`，索引的效率会下降。因为它们使得索引、索引的统计信息以及比较运算更加复杂，所以要求列值非空。
* **分析、检查、优化表**，MySQL中提供了analyze table语句分析表，使用analyze table分析表时，数据库系统会自动为表加一个只读锁；MySQL中可以使用check table语句来检查表，该语句能够检查innodb和MyISAM类型的表是否存在错误，使用过程中也会为表加上只读锁。MySQL中使用optimize table语句优化表，但只能优化varchar、blob、text类型，使用过程中也会给表加上只读锁。

注意：上述的这些方法都是有利有弊的，比如，修改数据类型可以节省空间，但同时你需要考虑是否会超出这个类型的存储范围，否则如果超出了范围，会造成严重的后果；增加冗余字段需要格外注意数据一致性；把大表拆分，意味着你的查询会增加连接操作，带来额外的开销和运维成本。



### 4、大表的优化

#### 限定查询范围

​	禁止任何不带任何限制数据范围条件的查询语句。比如在查询历史订单的时候，我们可以控制在一个月的范围内。

#### 读写分离

​	主库负责写，从库负责读。主要有一主一从模式、双主双从模式等。

#### 垂直拆分

​	当数据量级达到千万级以上时，有时候我们需要把一个数据库切成多份，放到不同的数据库服务器上，减少对单一数据库服务器的访问压力。垂直拆分的优点是可以使列数据变小，在查询时减少读取Block数，减少IO次数。此外，垂直分区可以简化表的结构，易于维护。缺点是主键会出现冗余，需要管理冗余列，并会引起JOIN操作。此外，垂直拆分会让事务变得更加复杂。

#### 水平拆分

​	数据库分片的两种方案：客户端代理，分片逻辑在应用端，封装在jar包，通过修改或者封装JDBC实现，当当网的Sharding-JDBC、阿里的TDDL是两种比较常用的实现。中间件代理，在应用和数据中间加了一个代理层，分片逻辑统一维护在中间件服务中，我们现在谈得Mycat，360的Atlas，网易得到DDB等等都是这种架构的实现。



### 5、其他调优策略

#### 服务器语句超时处理

​	在MySQL8.0中可以设置服务器语句超时的限制，单位可以达到毫秒级别。当中断的执行语句超过设置的毫秒数后，服务器将终止查询影响不大的事务或连接，然后将错误报告给客户端。可以通过设置系统变量MAX_EXECUTION_TIME来设置超时限制。

#### 创建全局通用表空间

#### 隐藏索引来进行调优






## 49、MySQL的undo日志记录的究竟是什么？如果记录的是还原sql，那么mvcc是如何使用undo日志做到快照读的？
  我的想法：undo日志中记录的不是还原sql，而是记录了更新之前的列属性，所以可以通过这个来还原数据，也可以通过这个来实现mvcc的快照读。



## 50、索引有哪些类型？

### 普通索引

​	不需要附加任何其他条件。

### 唯一索引

​	使用unique参数添加唯一索引，唯一索引的列值必须是唯一的，可以为空。一张表中可以有多个唯一索引。

### 主键索引

​	特殊的唯一索引，索引的值必须非空。一张表只能有一个主键索引，因为主键索引同时也是存放数据的结构。

### 全文索引

​	是目前搜索引擎使用的一种关键技术。它能利用分词技术等多种智能算法分析出文本文字中关键词的频率和重要性。使用参数FULLTEXT可以设置索引为全文索引。

### 单列索引

​	单列索引只根据一个字段进行索引，普通索引、唯一索引、全文索引都是单列索引。

### 多列索引

​	多列索引是在表的多个字段组合上创建一个索引。使用时遵循最左前缀原则。





## 51、哪些情况适合建立索引？哪些情况不适合建立索引？建立索引需要注意哪些事项？

适合建立索引的情况：

1、有唯一性约束的字段。

2、频繁作为where条件查询/更新/删除的字段。

3、经常group by和order by的字段。

4、join操作时，进行连接的字段可以考虑建立索引。

5、频繁distinct操作的字段可以考虑建立索引。

6、尽量使用列的值较小的字段建立索引，列的值小，占的空间就小，目录页中就可以存储更多的目录项，减少了读取页的次数，即减少了磁盘IO次数。

7、对于长度很长的字符串字段，例如TEXT类型、BLOG类型，使用前缀建立索引，这样虽然不能精确定位，但是节约了空间，减少了字符串比较时间。另一个缺点是前缀索引的字段不能用来order by。

8、区分度大的字段适合作为索引（第一点其实也算）。

9、如果建立联合索引，使用最频繁的列放在最左侧（最左前缀原则），这样能更大程度的利用联合索引。



不适合建立索引：

1、where中使用不到的字段。

2、有大量重复列值的字段。

3、数据量小的表不需要建立索引。

4、经常更新的表不要建太多索引。

5、不建议使用无序的值作为索引，例如UUID，在索引比较时需要转换成ASCII，并且插入时可能造成页分裂。



**建立索引需要注意：**索引并不是建立的越多越好，每个索引都需要占磁盘空间；索引会影响update、delete、create语句的性能，因为每一次修改都需要维护所有的索引；索引太多会影响查询优化器性能，因为优化器会对所有的索引进行分析，以生成一个最好的执行计划，如果有很多索引的话，会导致优化器分析过程耗时久，降低查询性能。



## 52、什么是幻读？可重复读隔离级别下会发生幻读吗？

​	幻读是指一个事务执行时，执行相同的select，前后两次结果不一致的情况。

​	可重复读隔离级别会发生幻读现象，不能完全避免幻读现象。

### 情况1

原表中数据：

![image-20230225104406710](D:\文档\学习笔记\学习疑问.assets\image-20230225104406710.png)

事务1：

![image-20230225104445566](D:\文档\学习笔记\学习疑问.assets\image-20230225104445566.png)

此时执行事务2，往表中添加数据：

![image-20230225104512942](D:\文档\学习笔记\学习疑问.assets\image-20230225104512942.png)

事务1再次执行，没有发生幻读现象：

![image-20230225104547032](D:\文档\学习笔记\学习疑问.assets\image-20230225104547032.png)

此时提交事务2，接着事务1执行update语句，并再次查询：

![image-20230225104808833](D:\文档\学习笔记\学习疑问.assets\image-20230225104808833.png)

发现查询结果竟然出现了两条记录，出现了幻读现象，前后两次查询结果不一致。这是因为update、delete、insert语句使用的是当前读，只有select查询使用的是快照读，所以update语句将事务2添加进来的记录也进行了修改，行记录中的最后一次修改的事务id也改为了当前事务，所以再次select时能够读取到。



### 情况2

开启事务1：

![image-20230225105358473](D:\文档\学习笔记\学习疑问.assets\image-20230225105358473.png)

接着开启事务2，并插入新纪录：

![image-20230225105438560](D:\文档\学习笔记\学习疑问.assets\image-20230225105438560.png)

接着事务1再次执行select语句，没有发生幻读现象：

![image-20230225105506583](D:\文档\学习笔记\学习疑问.assets\image-20230225105506583.png)

此时提交事务2，事务1执行如下语句：

![image-20230225105611892](D:\文档\学习笔记\学习疑问.assets\image-20230225105611892.png)

加上了共享锁，出现了幻读现象，我的猜测是使用了锁之后就放弃了快照读，而采用当前读，因为快照读机制就是为了避免加锁使用的，现在已经使用锁了，没必要再走快照读了。



## 53、主从复制中，如果主机宕机了，binlog还没有同步到从库上怎么办？

使用不同的数据复制方式来解决这个问题：

1、异步复制：主库写入binlog之后，不用等从库复制完成，直接返回结果给客户端（相当于事务结束了）。

2、半同步复制：主库写入binlog之后，收到一个从库的ack（同步完成后）才将结果返回给客户端。

3、组复制：基于paxos算法的复制方式，要提交一个结果，必须经过组内多数节点的同意。



## 54、有哪些产生死锁的情况？

​	1、select for update 会导致死锁的情况发生，如果两个事务要插入具有一个相同字段的记录，并且要求这个字段不能重复，那么两个事务都是先执行一个for update的查询，由于记录不存在，for update语句会加上间隙锁，由于间隙锁之间不冲突，所以两个事务都会加上间隙锁，后续再进行插入的时候就卡死。
